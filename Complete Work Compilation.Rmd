---
title: "Complete Work"
author: "Ross Cooper 54907605"
date: "2024-07-10"
output: html_document
---




# Data Cleaning and Processing

## Student grades data

The first thing we do is read in the student grades from the csv given. After that we trim the whitespace for all character columns to ensure there are no irregularities. A course code column is created to put a course with it's course number in the form COURSE.NUMBER.
```{r reading in student-data, eval = FALSE}
## this chunk is used to read in student grades data from student-data.csv
## and cleans the data to be used
df <- read.csv("..\\UBCO-Grade-Prediction-data\\student-data.csv")

df_clean <- df[,c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18)]

# Do some cleaning on chr columns
df_clean$STUD_NO_ANONYMOUS <- trimws(df_clean$STUD_NO_ANONYMOUS)
df_clean$CRS_DPT_CD <- trimws(df_clean$CRS_DPT_CD)
df_clean$HDR_CRS_LTTR_GRD <- trimws(df_clean$HDR_CRS_LTTR_GRD)
df_clean$CURR_SPEC_PRIM_PGM_TYPE_1 <- trimws(df_clean$CURR_SPEC_PRIM_PGM_TYPE_1)
df_clean$CURR_SPEC_PRIM_SUBJECT_1 <- trimws(df_clean$CURR_SPEC_PRIM_SUBJECT_1)
df_clean$CURR_SPEC_PRIM_PGM_TYPE_2 <- trimws(df_clean$CURR_SPEC_PRIM_PGM_TYPE_2)
df_clean$CURR_SPEC_PRIM_SUBJECT_2 <- trimws(df_clean$CURR_SPEC_PRIM_SUBJECT_2)
df_clean$CURR_SPEC_SECN_PGM_TYPE_1 <- trimws(df_clean$CURR_SPEC_SECN_PGM_TYPE_1)
df_clean$CURR_SPEC_SECN_SUBJECT_1 <- trimws(df_clean$CURR_SPEC_SECN_SUBJECT_1)
df_clean$CURR_SPEC_SECN_PGM_TYPE_2 <- trimws(df_clean$CURR_SPEC_SECN_PGM_TYPE_2)
df_clean$CURR_SPEC_SECN_SUBJECT_2 <- trimws(df_clean$CURR_SPEC_SECN_SUBJECT_2)
df_clean$DEGR_PGM_CD <- trimws(df_clean$DEGR_PGM_CD)
df_clean$SEC_SES_YR <- trimws(df_clean$SEC_SES_YR)
df_clean$SEC_NO <- trimws(df_clean$SEC_NO)
df_clean$SEC_SES_CD <- trimws(df_clean$SEC_SES_CD)


# Factor grades column
grades <-
  c("A+", "A", "A-", "B+", "B", "B-", "C+", "C", "C-", "D", "F")
df_clean$HDR_CRS_LTTR_GRD <-
  factor(df_clean$HDR_CRS_LTTR_GRD, levels = grades)

# Create course code column
df_clean$COURSE_CODE <- paste(df_clean$CRS_DPT_CD, df_clean$CRS_NO, sep = ".")
df_clean <- df_clean[,-(12:13)]

# Removing all withdrawl grades
df_clean <- df_clean[df_clean$HDR_CRS_PCT_GRD < 999,]

# Changing all withdrawls (999.9) to -1 to ensure they're kept in the data
#df_clean$HDR_CRS_PCT_GRD[df_clean$HDR_CRS_PCT_GRD == 999.9] <- -1

# Create year code column
df_clean$YEAR_CODE <- paste0(df_clean$SEC_SES_YR, df_clean$SEC_SES_CD)
df_clean <- df_clean[,-(15:16)]

# Removing 2023 grades (not included) [also does nothing bc ^ cleans it out]
#df_clean <- subset(df_clean, SEC_SES_YR < 2022.5)


# for if we want only BSc students (better to keep all data in)
#df_bsc <- df_clean[df_clean$DEGR_PGM_CD=="BSC-O",]


df_bsc
```

The student grades data has not fundamentally changed. 
```{r loading cleaned student-data, eval=TRUE}
load("student-data.RData")
head(df_bsc)
```

This chunks' main purpose is to make a table summing the number of times each course is taken. This also identifies the "Relevant Courses" as df_bsc_relevant_courses.
```{r finding number of times courses were taken, eval=FALSE}
# Determining how many bsc students took each course
unique(df_clean$COURSE_CODE)|>length()
# making a table indicating the number of times each course was taken
courses_taken_bsc <- table(df_bsc$COURSE_CODE)

# previous lines of code
# sorted_courses_taken_bsc <- sort(courses_taken_bsc, decreasing = TRUE)[1:200]
sorted_courses_taken_bsc <- sort(courses_taken_bsc, decreasing = TRUE)
# sorted_courses_taken_bsc <- sorted_courses_taken_bsc[substr(names(sorted_courses_taken_bsc),1,4) %in% c("DATA","MATH",
                                                   # "COSC","STAT")]

# current line which removes any courses not taken at least 10 times
# sorted_courses_taken_bsc <- sort(courses_taken_bsc[courses_taken_bsc >= 10], decreasing = TRUE)

# barplot showing # of times a course is taken
barplot(sorted_courses_taken_bsc)
# saving the course names of those which remain
course_names <- dimnames(sorted_courses_taken_bsc)[[1]]

# Subsetting on only courses which are taken 10 or more times ("relevant courses")
df_bsc_relevant_courses <- df_bsc[df_bsc$COURSE_CODE %in% course_names, ]

# Getting a list of all student ids which took relevant courses
uniqueids <- unique(df_bsc_relevant_courses$STUD_NO_ANONYMOUS)
```

This chunk was used to determine the maximum number of times each course was taken. With the number of times a course was taken, we can make enough columns for each students' retaken course grade without issue.
```{r counting course retake occurences, eval=FALSE}
# finding student who've taken a course more than once
duplicate_rows <- df_bsc_relevant_courses[duplicated(df_bsc_relevant_courses[c("STUD_NO_ANONYMOUS", "COURSE_CODE")]) | duplicated(df_bsc_relevant_courses[c("STUD_NO_ANONYMOUS", "COURSE_CODE")], fromLast = TRUE), ]
duplicate_rows[c(1,15,12,13)]

# Count occurrences of each course for each student
course_counts <- table(duplicate_rows$STUD_NO_ANONYMOUS, duplicate_rows$COURSE_CODE)

# Find the maximum number of times each course was taken by any student
max_repeats <- apply(course_counts, 2, max)

# Combine course names with corresponding maximum counts
max_course_counts_df <- data.frame(COURSE_CODE = names(max_repeats), max_repeats)
```

Here we create those columns header names to be able to create a empty dataframe to fill.
```{r creating list of course column names .1 .2, eval=FALSE}
# Creating a new list of course column names
## eg. Math.101.1, Math.101.2...

## want a list of course names with the .1 .2 .3
# groups: Non-Repeats, Repeats
# Non-repeats
non_rep_courses <- setdiff(course_names,max_course_counts_df$COURSE_CODE)

# Repeats
# Modify course names for repeated courses
rep_courses <- c()
for (i in 1:nrow(max_course_counts_df)) {
  for (j in 1:max_course_counts_df[i,2]) {
    rep_courses <- append(rep_courses, paste0(max_course_counts_df[i,1], ".", j))
  }
}

course_names_dups <- append(non_rep_courses, rep_courses)
```


### Extracting student majors and minors
This chunk is used to find each students' major(s), minor, and whether they are taking honors. They are saved in a dataframe with each student on a new row. This dataframe is later fed into the studentgrades dataframe including all student grades. This chunk will be run for any of the three types of students grade structure used.
```{r finding student majors and minors, eval=FALSE}
# Finding student majors and minors
### WARNING: no 2023 data yet which may contain updates to major/minors


# looking through/ getting last row of each student
library(dplyr)

# Assuming your dataframe is called 'df'

# Group by student_id and get the last row of each group
last_rows <- df_bsc_relevant_courses %>%
  group_by(STUD_NO_ANONYMOUS) %>%
  slice(n())


# Create a data frame with NA values and course column names
new_columns <- data.frame(matrix(NA, nrow = nrow(last_rows), ncol = 4))


# Add course name columns to existing data frame
student_mm <- cbind(last_rows[,1], new_columns)
colnames(student_mm) <- c("StudentID", "Major.1", "Major.2", "Minor", "Honors")
student_mm$Honors <- FALSE

for(i in 1:nrow(last_rows)){
  # If MAJ is in column 1, major.1 is that subject
  if(last_rows[i,]$CURR_SPEC_PRIM_PGM_TYPE_1=="MAJ"){
    student_mm[i,]$Major.1 <- last_rows[i,]$CURR_SPEC_PRIM_SUBJECT_1
  }
  
  # if MAJ is in col 2, check if major.1 is occupied and place it in maj.1 or maj.2
  if(last_rows[i,]$CURR_SPEC_PRIM_PGM_TYPE_2=="MAJ" & is.na(student_mm[i,]$Major.1)){
    student_mm[i,]$Major.1 <- last_rows[i,]$CURR_SPEC_PRIM_SUBJECT_2
  } else if (last_rows[i,]$CURR_SPEC_PRIM_PGM_TYPE_2=="MAJ"){
    student_mm[i,]$Major.2 <- last_rows[i,]$CURR_SPEC_PRIM_SUBJECT_2
  }
  
  # combined majors....
  
  # finding that minor
  if(last_rows[i,]$CURR_SPEC_PRIM_PGM_TYPE_1=="MIN"){
    student_mm[i,]$Minor <- last_rows[i,]$CURR_SPEC_PRIM_SUBJECT_1
  } else if (last_rows[i,]$CURR_SPEC_PRIM_PGM_TYPE_2=="MIN"){
    student_mm[i,]$Minor <- last_rows[i,]$CURR_SPEC_PRIM_SUBJECT_2
  }
  
  # adding Honors as majors
  if(last_rows[i,]$CURR_SPEC_PRIM_PGM_TYPE_1=="HON" & is.na(student_mm[i,]$Major.1)){
    student_mm[i,]$Major.1 <- last_rows[i,]$CURR_SPEC_PRIM_SUBJECT_1
    student_mm[i,]$Honors <- TRUE
  } else if (last_rows[i,]$CURR_SPEC_PRIM_PGM_TYPE_1=="HON" & is.na(student_mm[i,]$Major.2)){
    student_mm[i,]$Major.2 <- last_rows[i,]$CURR_SPEC_PRIM_SUBJECT_1
    student_mm[i,]$Honors <- TRUE
  }
  if(last_rows[i,]$CURR_SPEC_PRIM_PGM_TYPE_2=="HON" & is.na(student_mm[i,]$Major.1)){
    student_mm[i,]$Major.1 <- last_rows[i,]$CURR_SPEC_PRIM_SUBJECT_2
    student_mm[i,]$Honors <- TRUE
  } else if (last_rows[i,]$CURR_SPEC_PRIM_PGM_TYPE_2=="HON" & is.na(student_mm[i,]$Major.2)){
    student_mm[i,]$Major.2 <- last_rows[i,]$CURR_SPEC_PRIM_SUBJECT_2
    student_mm[i,]$Honors <- TRUE
  }
  
  # adding combined majors
  if(last_rows[i,]$CURR_SPEC_PRIM_PGM_TYPE_1=="CMJ"){
    student_mm[i,]$Major.1 <- last_rows[i,]$CURR_SPEC_PRIM_SUBJECT_1
    student_mm[i,]$Major.2 <- last_rows[i,]$CURR_SPEC_SECN_SUBJECT_1
  } else if (last_rows[i,]$CURR_SPEC_PRIM_PGM_TYPE_2=="CMJ" & !is.na(student_mm[i,]$Major.1)){
    student_mm[i,]$Major.2 <- last_rows[i,]$CURR_SPEC_PRIM_SUBJECT_2
  }
  
}
head(student_mm)
```



# Data Structure
## Using all student grades from retaken courses

This variation of studentgrades has each student represented as rows, and courses as columns. Course grades are recorded for each attempt a student takes at each course. Each new attempt is saved in a new column with all 3rd time attemps of MATH.101 being saved in MATH.101.3. For example, MATH 101 has 3 columns: MATH.101.1, MATH.101.2, MATH.101.3. One for each new attempt at MATH 101.

Here we create an empty dataframe, add in the unique student ids and their matching majors and minors. After we loop through df_bsc_relevant_courses to add in grades to their respective student and course column.
```{r Making studentgrades with .1 .2 etc, eval=FALSE}
# Making the Data Frame
 ## Columns to add: Student ID, Major, Honors, Minor, Extras, 200 most common courses

# Building df after getting the data

studentgrades <- data.frame(Student_ID = sort(uniqueids))




# Create a data frame with NA values and course column names
new_columns <- data.frame(matrix(NA, nrow = nrow(studentgrades), ncol = length(course_names_dups)))
colnames(new_columns) <- course_names_dups

# Add course name columns to existing data frame
studentgrades <- cbind(studentgrades, student_mm[,-1], new_columns)


# Saving student grades into df
for (i in 1:nrow(df_bsc_relevant_courses)){
  rep <- 0
  # finding the index of course name .1
  coursecol <- grep(df_bsc_relevant_courses[i,]$COURSE_CODE, colnames(studentgrades))[1]
  
  # Moving over from .1 to .2 columns if a grade already exists
  while(!is.na(studentgrades[studentgrades$Student_ID==df_bsc_relevant_courses[i,]$STUD_NO_ANONYMOUS,coursecol+rep])){
    rep = rep+1
  }
  
  # Saving student grade into studentgrades df
  studentgrades[studentgrades$Student_ID==df_bsc_relevant_courses[i,]$STUD_NO_ANONYMOUS,coursecol+rep] <- df_bsc_relevant_courses[i,]$HDR_CRS_PCT_GRD
}

studentgrades[,c("Student_ID","MATH.101.1","MATH.101.2")]


```

```{r loading studentgrades with .1 .2, eval=TRUE}
load(file = "studentgrades_1.RData")
head(studentgrades)
```



## Using only the most recent course grades

This variation of studentgrades has each student represented as rows, and courses as columns. Only the most recent attempt at each course is recorded. For example, MATH 101 has only one column: MATH.101.

```{r Making studentgrades using most recent grade, eval=FALSE}
studentgrades <- data.frame(Student_ID = sort(uniqueids))

# Create a data frame with NA values and course column names
new_columns <- data.frame(matrix(NA, nrow = nrow(studentgrades), ncol = length(course_names)))
colnames(new_columns) <- course_names

# Add course name columns to existing data frame
studentgrades <- cbind(studentgrades, student_mm[,-1], new_columns)


# Saving student grades into df
for (i in 1:nrow(df_bsc_relevant_courses)){
  
  # finding the index of course name .1
  coursecol <- grep(df_bsc_relevant_courses[i,]$COURSE_CODE, colnames(studentgrades))[1]
  
  # Saving student grade into studentgrades df
  studentgrades[studentgrades$Student_ID==df_bsc_relevant_courses[i,]$STUD_NO_ANONYMOUS,coursecol] <- df_bsc_relevant_courses[i,]$HDR_CRS_PCT_GRD
}

studentgrades
```

```{r loading studentgrades using most recent grade, eval=TRUE}
load("StudentGrades.RData")
head(studentgrades)
```



## Using Professor data
### Cleaning process
```{r compiling prof csv data, eval=FALSE}
# getting all file names in UBCO-Profs folder
file_names <- dir(path = "UBCO-Profs")

# full prof dataframe
course_profs <- data.frame(Professor=character(), year_code=character(), course_name=character(), Section=character())

for(i in 1:length(file_names)){
  # Try to open the file connection
  file_connection <- try(read.csv(paste0("UBCO-Profs/", file_names[i])), silent = TRUE)

  # Check if the connection was successful
  if (inherits(file_connection, "try-error")) {
    
  } else {
    df <- file_connection
    df$course_name <- paste(file_connection$Subject, file_connection$Course, sep = ".")
    df$year_code <- paste0(file_connection$Year, file_connection$Session)
    df <- df[,c("Professor", "year_code", "course_name", "Section")]
    
    course_profs <- rbind(course_profs, df)
  }

}

# both of these have no prof names
course_profs <- course_profs[course_profs$Section != "OVERALL",]
course_profs <- course_profs[course_profs$Professor != "",]

save(course_profs, file = "course_profs.RData")
```

```{r adjusting prof data table, eval=FALSE}
# all unique 'professor' names
prof_names_full_data <- course_profs$Professor
# length
len <- length(prof_names_full_data)

# empty vectors
prof_names_all <- character()
prof_lens <- numeric()

# looping through to fill two vectors
for(i in 1:len){
  # adding all names to a pile of names (yes duplicates)
  prof_names_all <-  c(prof_names_all, strsplit(prof_names_full_data[i], ";")[[1]])
  # adding each unique 'professor' name's length (ie. # of profs)
  prof_lens <- c(prof_lens, length(strsplit(prof_names_full_data[i], ";")[[1]]))
}

# DF of all 'prof' names with more than one person
# course_profs[which(prof_lens > 1),]


# creating a table count of # of times profs taught
prof_table <- table(prof_names_all)
ordered_profs <- sort(prof_table, decreasing = TRUE)
```

```{r making table of courses and their professors, eval=FALSE}
# making a new table to join on (to student grades)
rel_course_profs <- course_profs
ordered_prof_names <- rownames(ordered_profs)


# loop through all rows
for(r in 1:nrow(rel_course_profs)){
  
  # if professor has more than one prof
  if(length(strsplit(rel_course_profs[r,"Professor"],";")[[1]]) > 1){
    
    # loop through prof names to save first one which appears
    for(i in 1:length(ordered_prof_names)){
      
      # checking if current ordered prof is in list of profs
      if(ordered_prof_names[i] %in% strsplit(rel_course_profs[r,"Professor"],";")[[1]]){
          rel_course_profs[r,"Professor"] <- ordered_prof_names[i]
          break
      }
      
    }
  }
    
}


save(rel_course_profs, file = "cleaned_profs.RData")
```

```{r loading professor cleaning and final data}
# course_profs
load("course_profs.RData")
# rel_course_profs
load("cleaned_profs.RData")
```

The dataframe rel_course_profs contains rows containing the Professor, Year, Course name, and Section for each course and section from 2018S to 2023S.


### Data structure

```{r adding profs to studentgrades *OLD*, eval=FALSE}
courses <- unique(rel_course_profs$course_name)
courses <- colnames(studentgrades[,colnames(studentgrades) %in% courses])

courseprof_cols <- c(courses, paste0(courses,".P"))


# cbind(studentgrades[,c(1:5)],studentgrades[,colnames(studentgrades) %in% courses])

# cutting out all courses which will cause prof error
df_bsc_relevant_courses <- df_bsc[df_bsc$COURSE_CODE %in% courses,]

# adding in professors
matching_profs <- character()
for(i in 1:nrow(df_bsc_relevant_courses)){
  if(length(rel_course_profs[rel_course_profs$year_code == df_bsc_relevant_courses[i,"YEAR_CODE"] & 
                   rel_course_profs$course_name == df_bsc_relevant_courses[i,"COURSE_CODE"] & 
                   rel_course_profs$Section == df_bsc_relevant_courses[i,"SEC_NO"],]$Professor) == 0){
    matching_profs <- c(matching_profs, NA)
    # next
    
  } else {
    matching_profs <- c(matching_profs, rel_course_profs[rel_course_profs$year_code == df_bsc_relevant_courses[i,"YEAR_CODE"] & 
                   rel_course_profs$course_name == df_bsc_relevant_courses[i,"COURSE_CODE"] & 
                   rel_course_profs$Section == df_bsc_relevant_courses[i,"SEC_NO"],]$Professor)
  }
}

rel_course_profs[rel_course_profs$year_code == df_bsc_relevant_courses[i,"YEAR_CODE"] & 
                   rel_course_profs$course_name == df_bsc_relevant_courses[i,"COURSE_CODE"] & 
                   rel_course_profs$Section == df_bsc_relevant_courses[i,"SEC_NO"],]$Professor


length(matching_profs)
nrow(df_bsc_relevant_courses)

# creating list of unique ids
uniqueids <- unique(df_bsc_relevant_courses$STUD_NO_ANONYMOUS)

### from another chunk
studentgrades_prof <- data.frame(Student_ID = sort(uniqueids))

# Create a data frame with NA values and course column names
new_columns <- data.frame(matrix(NA, nrow = nrow(studentgrades_prof), ncol = length(courseprof_cols)))
colnames(new_columns) <- courseprof_cols

# Add course name columns to existing data frame
studentgrades_prof <- cbind(studentgrades_prof, student_mm[,-1], new_columns)


prof_column_adjust <- length(courses)

# Saving student grades into df
for (i in 1:nrow(df_bsc_relevant_courses)){
  
  ## we have two 36,000 length things, df_bsc_rel_courses and matching_profs
  ## need to pull grades from df and profs from match_profs ROW BY ROW
  ## add to studengrades_prof, can split using + length(courses) between course and prof columns
  
  # finding the index of course name .1
  coursecol <- grep(df_bsc_relevant_courses[i,]$COURSE_CODE, colnames(studentgrades_prof))[1]
  
  # Saving student grade into studentgrades_prof df
  studentgrades_prof[studentgrades_prof$Student_ID==df_bsc_relevant_courses[i,]$STUD_NO_ANONYMOUS,coursecol] <- df_bsc_relevant_courses[i,]$HDR_CRS_PCT_GRD
  
  # saving prof name into studentgrades_prof df
  studentgrades_prof[studentgrades_prof$Student_ID==df_bsc_relevant_courses[i,]$STUD_NO_ANONYMOUS,coursecol+prof_column_adjust] <- matching_profs[i]
}

studentgrades_prof[,880:890]
```

```{r creating studentgrades_prof, eval=FALSE}
# creating all columns to be used in studentgrades_prof
# course_names from 'finding number of times courses were taken' chunk
courseprof_cols <- c(course_names, paste0(course_names,".P"))


# creating list of unique ids
uniqueids <- unique(df_bsc_relevant_courses$STUD_NO_ANONYMOUS)

### from another chunk
studentgrades_prof <- data.frame(Student_ID = sort(uniqueids))

# Create a data frame with NA values and course column names
new_columns <- data.frame(matrix(NA, nrow = nrow(studentgrades_prof), ncol = length(courseprof_cols)))
colnames(new_columns) <- courseprof_cols

# Add course name columns to existing data frame
studentgrades_prof <- cbind(studentgrades_prof, student_mm[,-1], new_columns)


prof_column_adjust <- length(course_names)

# Saving student grades into df
for (i in 1:nrow(df_bsc_relevant_courses)){
  
  
  # finding the index of course name
  coursecol <- grep(df_bsc_relevant_courses[i,]$COURSE_CODE, colnames(studentgrades_prof))[1]
  
  # Saving student grade into studentgrades_prof df
  studentgrades_prof[studentgrades_prof$Student_ID==df_bsc_relevant_courses[i,]$STUD_NO_ANONYMOUS,coursecol] <- df_bsc_relevant_courses[i,]$HDR_CRS_PCT_GRD
  
  # catching if there is no prof for course
  if(length(rel_course_profs[rel_course_profs$year_code == df_bsc_relevant_courses[i,"YEAR_CODE"] & 
                   rel_course_profs$course_name == df_bsc_relevant_courses[i,"COURSE_CODE"] & 
                   rel_course_profs$Section == df_bsc_relevant_courses[i,"SEC_NO"],]$Professor) == 1){
    
    
    # saving prof name into studentgrades_prof df
  studentgrades_prof[studentgrades_prof$Student_ID==df_bsc_relevant_courses[i,]$STUD_NO_ANONYMOUS,coursecol+prof_column_adjust] <- rel_course_profs[rel_course_profs$year_code == df_bsc_relevant_courses[i,"YEAR_CODE"] & 
                   rel_course_profs$course_name == df_bsc_relevant_courses[i,"COURSE_CODE"] & 
                   rel_course_profs$Section == df_bsc_relevant_courses[i,"SEC_NO"],]$Professor
  }
  
  # catching if there are more than one prof showed (PSYO 380 since it's missing 'Detail' in main student grades csv)
  if(length(rel_course_profs[rel_course_profs$year_code == df_bsc_relevant_courses[i,"YEAR_CODE"] & 
                   rel_course_profs$course_name == df_bsc_relevant_courses[i,"COURSE_CODE"] & 
                   rel_course_profs$Section == df_bsc_relevant_courses[i,"SEC_NO"],]$Professor) > 1){
    
    
    # saving prof name into studentgrades_prof df
  studentgrades_prof[studentgrades_prof$Student_ID==df_bsc_relevant_courses[i,]$STUD_NO_ANONYMOUS,coursecol+prof_column_adjust] <- rel_course_profs[rel_course_profs$year_code == df_bsc_relevant_courses[i,"YEAR_CODE"] & 
                   rel_course_profs$course_name == df_bsc_relevant_courses[i,"COURSE_CODE"] & 
                   rel_course_profs$Section == df_bsc_relevant_courses[i,"SEC_NO"],]$Professor[1]
  }
  
  
}

studentgrades_prof


# removing columns with no or one prof
cols_to_remove <- numeric(0)
for(i in (prof_column_adjust+6):ncol(studentgrades_prof)){
  if(length(unique(studentgrades_prof[,i])) <= 2){
    cols_to_remove <- c(cols_to_remove, i)
  }
}

studentgrades_prof <- studentgrades_prof[,-cols_to_remove]


# factoring professor columns
for(i in (prof_column_adjust+6):ncol(studentgrades_prof)){
  studentgrades_prof[,i] <- factor(studentgrades_prof[,i])
}

save(studentgrades_prof, file="Prof_StudentGrades.RData")
```

```{r loading studentgrades_prof}
# studentgrades_prof
load(file="Prof_StudentGrades.RData")
```

The dataframe studentgrades_prof is similar to studentgrades (most recent grades version) in that students grades are saved as rows, and each columns is a different course. Additionally, there are columns which contain the professors who taught each course there is a grade for. For example, Student X has a grade in the MATH.101 column and will therefore have a professor in the MATH.101.P column. Student Y who has not taken MATH 101 will not have a grade in MATH.101, nor a professor in MATH.101.P.



# Analysis and Prediction

## Initial EDA
```{r loading studentgrades with .1 .2 for initial EDA}
load(file = "studentgrades_1.RData")
```

```{r plot of MATH.100.1 against MATH.100.2}
# Big ol graph of student grades
maths <- studentgrades[complete.cases(studentgrades$MATH.100.1, studentgrades$MATH.100.2), ]


maths.lm <- lm(maths$MATH.100.1~ maths$MATH.100.2)
summary(maths.lm)

plot(maths$MATH.100.1, maths$MATH.100.2)
abline(maths.lm)

## weird....
```

```{r plot of MATH.100.1 against STAT.230.1}
mathstat <- studentgrades[complete.cases(studentgrades$MATH.100.1, studentgrades$STAT.230.1), ]

mathstat.lm <- lm(mathstat$MATH.100.1~ mathstat$STAT.230.1)
summary(mathstat.lm)

plot(mathstat$MATH.100.1, mathstat$STAT.230.1)
abline(mathstat.lm)

## this one is a little more normal
## could be issues with course retakers

## want to check on people who only had to take it once...
```

```{r plot of MATH.100.1 against PSYO.111.1}
edasubset <- studentgrades[complete.cases(studentgrades$MATH.100.1, studentgrades$PSYO.111.1), ]

edasubset.lm <- lm(edasubset$MATH.100.1~ edasubset$PSYO.111.1)
summary(edasubset.lm)

plot(edasubset$MATH.100.1, edasubset$PSYO.111.1)
abline(edasubset.lm)

## ... makes sense that some courses like PSYO 111 are grade boosters
```

```{r plot of MATH.100.2 against STAT.230.1}
mathstat2 <- studentgrades[complete.cases(studentgrades$MATH.100.2, studentgrades$STAT.230.1), ]

mathstat2.lm <- lm(mathstat2$MATH.100.2~ mathstat2$STAT.230.1)
summary(mathstat2.lm)

plot(mathstat2$MATH.100.2, mathstat2$STAT.230.1)
abline(mathstat2.lm)
```

```{r plot of MATH.100.1 (no MATH.100.2 grade present) againt STAT.230.1}

## want to check on people who only had to take it once (aka no MATH.100.2 grade present)

firsttimer <- anti_join(mathstat,mathstat2)
first.lm <- lm(firsttimer$MATH.100.1~ firsttimer$STAT.230.1)
summary(first.lm)

plot(firsttimer$MATH.100.1, firsttimer$STAT.230.1, xlim = c(0,100))
abline(first.lm)

# just removed the 'low' grades (p much all fails) 
```

```{r finding average grades for each course}
# want the average grade for each course... bar plot
course_averages <- data.frame(Courses = course_names_dups, Average = rep(NA, length(course_names_dups)))

for (i in 1:nrow(course_averages)){
  course_averages[i,]$Average <- mean(studentgrades[,course_averages[i,1]],na.rm = TRUE)
}

# barplot of all course average grades
barplot(course_averages$Average, names.arg = course_averages$Courses)

# average grades for each course
head(course_averages)
```

```{r pairplot of MATH.100.1, MATH.101.1, STAT.230.1, DATA.101.1}
# pairplot using data which has no missing grades from these courses
plot(studentgrades[!is.na(studentgrades$MATH.100.1)&!is.na(studentgrades$MATH.101.1)&!is.na(studentgrades$STAT.230.1)&!is.na(studentgrades$DATA.101.1),c("Student_ID","MATH.100.1","MATH.101.1","STAT.230.1","DATA.101.1")])

# studentgrades data which has no missing STAT.230 grades
studentgrades[!is.na(studentgrades$STAT.230.1),c("Student_ID","MATH.100.1","MATH.101.1","DATA.101.1","STAT.230.1")]

# pairplot using data which has no missing STAT.230 grades
plot(studentgrades[!is.na(studentgrades$STAT.230.1),c("Student_ID","MATH.100.1","MATH.101.1","DATA.101.1","STAT.230.1")])
```

```{r plot of MATH.100.1 against MATH.101.1}
plot(studentgrades[!is.na(studentgrades$MATH.100.1)&!is.na(studentgrades$MATH.101.1),c("MATH.100.1","MATH.101.1")])
```

```{r number of times courses have been taken by those who have taked STAT 230, eval=FALSE}
# returns the number of times a course has been taken by students WHO HAVE ALL TAKEN stat 230
ids <- unique(df_bsc_relevant_courses[df_bsc_relevant_courses$COURSE_CODE=="STAT.230",]$STUD_NO_ANONYMOUS)
courses <- unique(df_bsc_relevant_courses[df_bsc_relevant_courses$STUD_NO_ANONYMOUS %in% ids,]$COURSE_CODE)
new_courses <- character(0)
for(i in 1:length(courses)){
  if(strsplit(courses[i], split = ".", fixed = TRUE)[[1]][2] < 300){
    new_courses <- append(new_courses, courses[i])
  }
}

courses_taken_bsc_stat230 <- table(df_bsc_relevant_courses[df_bsc_relevant_courses$STUD_NO_ANONYMOUS %in% ids & df_bsc_relevant_courses$COURSE_CODE %in% new_courses,]$COURSE_CODE)


sorted_courses_taken_bsc <- sort(courses_taken_bsc_stat230, decreasing = TRUE)
sorted_courses_taken_bsc

# number of courses who have been taken by at least N people: 25 people = 105 courses | 250 people = 25 courses
N = 25
length(sorted_courses_taken_bsc[sorted_courses_taken_bsc >= N])


```

## First Prediction Attempts
### MissForest
```{r missForest Impute into RF on course first attempts, eval=FALSE}
# preparing all student grades with stat230
stat230grades <- studentgrades[!is.na(studentgrades$STAT.230.1),c("Student_ID","MATH.100.1","MATH.101.1","STAT.230.1","MATH.200.1","MATH.221.1","COSC.211.1","COSC.222.1","COSC.221.1")]
stat230grades

library(missForest)
library(randomForest)

n_rows <- nrow(stat230grades)

train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing



stat230.imputed <- missForest(stat230grades[,2:5])$ximp

stat230.rf <- randomForest(STAT.230.1~., data=stat230.imputed[train_indices,] )
stat230.pred <- predict(stat230.rf, newdata = stat230.imputed[test_indices,])

stat230.real <- stat230grades[test_indices,]$STAT.230.1

# MSE value to compare to other models
mse <- mean((stat230.pred - stat230.real)^2)
mse
```

```{r missForest Impute into RF NEW USING NEW studentgrades, eval=TRUE}
# preparing all student grades with stat230
stat230grades <- studentgrades[!is.na(studentgrades$STAT.230),c("Student_ID","MATH.100","MATH.101","STAT.230","MATH.200","MATH.221","COSC.211","COSC.222","COSC.221")]
stat230grades

library(missForest)
library(randomForest)

n_rows <- nrow(stat230grades)

train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing



stat230.imputed <- missForest(stat230grades[,2:5])$ximp

stat230.rf <- randomForest(STAT.230~., data=stat230.imputed[train_indices,] )
stat230.pred <- predict(stat230.rf, newdata = stat230.imputed[test_indices,])

stat230.real <- stat230grades[test_indices,]$STAT.230

# MSE value to compare to other models
mse <- mean((stat230.pred - stat230.real)^2)
mse
```

```{r missForest Impute into RF using more courses, eval=TRUE}
load("StudentGrades.RData")

set.seed(5934)
# preparing all student grades with stat230
stat230grades <- studentgrades[!is.na(studentgrades$STAT.230),c("Student_ID","MATH.100","MATH.101","STAT.230","MATH.200","MATH.221","COSC.211","COSC.222","COSC.221")]
stat230grades

library(missForest)
library(randomForest)

n_rows <- nrow(stat230grades)

train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing



stat230.imputed <- missForest(stat230grades[,2:9])$ximp

stat230.rf <- randomForest(STAT.230~., data=stat230.imputed[train_indices,] )
stat230.pred <- predict(stat230.rf, newdata = stat230.imputed[test_indices,])

stat230.real <- stat230grades[test_indices,]$STAT.230

# MSE value to compare to other models
mse <- mean((stat230.pred - stat230.real)^2)
mse

# graphs
## predicted vs actual plot
predictions <- stat230.pred
actual <- stat230.real

actual <- coursegrades[test_indices,]$STAT.230
plot(actual, predictions, xlab = "Actual Grades", ylab = "Predicted Grades", 
     main = "Predicted vs Actual Grades", pch = 16, col = "blue", xlim = c(0,100), ylim = c(0,100))
abline(0, 1, col = "red")

line.lm <- lm(predictions~actual)
abline(line.lm, col = "green")


## residuals plot
residuals <- actual - predictions
plot(predictions, residuals, xlab = "Predicted Grades", ylab = "Residuals", 
     main = "Residual Plot", pch = 16, col = "blue")
abline(h = 0, col = "red")

line.lm <- lm(residuals~predictions)
abline(line.lm, col = "green")


## qq plots
qqnorm(residuals, main = "Normal Q-Q Plot of Residuals")
qqline(residuals, col = "red")


# reload .1 .2 grades to not mess up later chunks
load(file = "studentgrades_1.RData")
```

```{r Using missForest for prediction, eval=TRUE}
set.seed(5934)
# preparing all student grades with stat230
stat230grades <- studentgrades[!is.na(studentgrades$STAT.230),-1:-5]
stat230grades

library(missForest)
library(randomForest)

n_rows <- nrow(stat230grades)

train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing

# to remove stat 230 grades from test_indicies rows
stat230.real <- stat230grades[test_indices,]$STAT.230
stat230grades[test_indices,]$STAT.230 <- NA

stat230.imputed <- missForest(stat230grades)$ximp

#stat230.rf <- randomForest(STAT.230~., data=stat230.imputed[train_indices,] )
#stat230.pred <- predict(stat230.rf, newdata = stat230.imputed[test_indices,])
stat230.pred <- stat230.imputed[test_indices,]$STAT.230


# MSE value to compare to other models
mse <- mean((stat230.pred - stat230.real)^2)
mse
```


### Random Forest
```{r RF on all non-NA data, eval=TRUE}
# getting all students with grades in all courses
stat230grades.full <- studentgrades[!is.na(studentgrades$MATH.100.1)&!is.na(studentgrades$MATH.101.1)&!is.na(studentgrades$STAT.230.1)&!is.na(studentgrades$DATA.101.1),c("Student_ID","MATH.100.1","MATH.101.1","STAT.230.1","DATA.101.1")]
stat230grades.full

n_rows <- nrow(stat230grades.full)

train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing

library(randomForest)

stat230.rf <- randomForest(STAT.230.1~., data=stat230grades.full[train_indices,2:5] )
stat230.pred <- predict(stat230.rf, newdata = stat230grades.full[test_indices,2:5])

stat230.real <- stat230grades.full[test_indices,2:5]$STAT.230.1

# MSE value to compare to other models
mse <- mean((stat230.pred - stat230.real)^2)
mse

## MSE of data without DATA101 is 175...
## looks like imputing data and running a randomforest is best so far
```

```{r RF on complete data, eval=TRUE}
# this chunk uses a random forest model trained on the complete set of STAT 230, MATH 101, and COSC.221 (aka no NAs between them)
coursegrades <- studentgrades[!is.na(studentgrades$STAT.230)&!is.na(studentgrades$MATH.101)&!is.na(studentgrades$COSC.221),c("STAT.230","MATH.101","COSC.221")]

set.seed(5934)

library(randomForest)

n_rows <- nrow(coursegrades)

train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing



stat230.rf <- randomForest(STAT.230~., data=coursegrades[train_indices,] )
stat230.pred <- predict(stat230.rf, newdata = coursegrades[test_indices,])



# MSE value to compare to other models
mse <- mean((stat230.pred - stat230.real)^2)
mse
```

```{r missForest Impute into RF on few specific courses (stats maths cosc), eval=TRUE}
# preparing all student grades with stat230
stat230grades <- studentgrades[!is.na(studentgrades$STAT.230),c("Student_ID","MATH.100","MATH.101","STAT.230","MATH.200","MATH.221","COSC.211","COSC.222","COSC.221")]
stat230grades

library(missForest)
library(randomForest)

n_rows <- nrow(stat230grades)

train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing



stat230.imputed <- missForest(stat230grades[,2:9])$ximp

stat230.rf <- randomForest(STAT.230~., data=stat230.imputed[train_indices,])
predictions <- predict(stat230.rf, newdata = stat230.imputed[test_indices,])

stat230.real <- stat230grades[test_indices,]$STAT.230

# RMSE value to compare to other models
rmse <- sqrt(mean((predictions - stat230.real)^2))
rmse
```

```{r missForest Impute into RF on all courses taken x times, eval=TRUE}
# returns the number of times a course has been taken by students who have also taken stat 230
ids <- unique(df_bsc_relevant_courses[df_bsc_relevant_courses$COURSE_CODE=="STAT.230",]$STUD_NO_ANONYMOUS)
courses <- unique(df_bsc_relevant_courses[df_bsc_relevant_courses$STUD_NO_ANONYMOUS %in% ids,]$COURSE_CODE)
new_courses <- character(0)
for(i in 1:length(courses)){
  if(strsplit(courses[i], split = ".", fixed = TRUE)[[1]][2] < 300){
    new_courses <- append(new_courses, courses[i])
  }
}

courses_taken_bsc_stat230 <- table(df_bsc_relevant_courses[df_bsc_relevant_courses$STUD_NO_ANONYMOUS %in% ids & df_bsc_relevant_courses$COURSE_CODE %in% new_courses,]$COURSE_CODE)


sorted_courses_taken_bsc <- sort(courses_taken_bsc_stat230, decreasing = TRUE)

##
## Filter course names used base on how many people have taken those predictor courses
##
course_names <- sorted_courses_taken_bsc[sorted_courses_taken_bsc >= 190]


course_names <- dimnames(course_names)[[1]]


coursegrades <- studentgrades[!is.na(studentgrades$STAT.230),colnames(studentgrades) %in% course_names]
head(coursegrades)

library(missForest)
library(randomForest)

set.seed(5934)
n_rows <- nrow(coursegrades)

train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing



stat230.imputed <- missForest(coursegrades[,-1])$ximp

stat230.rf <- randomForest(STAT.230~., data=stat230.imputed[train_indices,])
predictions <- predict(stat230.rf, newdata = stat230.imputed[test_indices,])

stat230.real <- coursegrades[test_indices,]$STAT.230

# RMSE value to compare to other models
rmse <- sqrt(mean((predictions - stat230.real)^2))
rmse
```

```{r missForest Impute into RF on all courses *USED FOR TESTING ON DIFF COURSES* (COSC.221)}
# returns the number of times a course has been taken by students who have also taken xxxx.xxx
ids <- unique(df_bsc_relevant_courses[df_bsc_relevant_courses$COURSE_CODE=="COSC.221",]$STUD_NO_ANONYMOUS)
courses <- unique(df_bsc_relevant_courses[df_bsc_relevant_courses$STUD_NO_ANONYMOUS %in% ids,]$COURSE_CODE)
new_courses <- character(0)
for(i in 1:length(courses)){
  if(strsplit(courses[i], split = ".", fixed = TRUE)[[1]][2] < 300){
    new_courses <- append(new_courses, courses[i])
  }
}

courses_taken_bsc_stat230 <- table(df_bsc_relevant_courses[df_bsc_relevant_courses$STUD_NO_ANONYMOUS %in% ids & df_bsc_relevant_courses$COURSE_CODE %in% new_courses,]$COURSE_CODE)


sorted_courses_taken_bsc <- sort(courses_taken_bsc_stat230, decreasing = TRUE)
course_names <- sorted_courses_taken_bsc[sorted_courses_taken_bsc >= 50]



set.seed(45)

# of the same year and below
# preparing all student grades with stat230
course_names <- dimnames(course_names)[[1]]



course_names <- c("COSC.121","MATH.200","MATH.221","COSC.221","COSC.211","MATH.101","COSC.222","ECON.101","COSC.111","PSYO.111","STAT.230")

stat230grades <- studentgrades[!is.na(studentgrades$COSC.221),colnames(studentgrades) %in% course_names]
stat230grades

library(missForest)
library(randomForest)

n_rows <- nrow(stat230grades)

train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing



stat230.imputed <- missForest(stat230grades[,-1])$ximp

stat230.rf <- randomForest(COSC.221~., data=stat230.imputed[train_indices,])
stat230.pred <- predict(stat230.rf, newdata = stat230.imputed[test_indices,])

stat230.real <- stat230grades[test_indices,]$COSC.221

# MSE value to compare to other models
rmse <- sqrt(mean((stat230.pred - stat230.real)^2))
rmse

```

### Gradient Boosted Machines
```{r GBM on partial-NA data, eval=TRUE}
# loading in data again
stat230grades <- studentgrades[!is.na(studentgrades$STAT.230.1),c("Student_ID","MATH.100.1","MATH.101.1","DATA.101.1","STAT.230.1")]
n_rows <- nrow(stat230grades)
train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing

library(gbm)

gbm_params <- list(
  distribution = "gaussian",  # Specify the distribution for regression
  n.trees = 100,               # Number of trees (iterations)
  interaction.depth = 4,       # Maximum depth of trees
  shrinkage = 0.1,             # Learning rate (shrinkage)
  bag.fraction = 0.5,          # Fraction of training data used for each tree
  train.fraction = 1.0,        # Fraction of training data used for training (1.0 for full dataset)
  n.minobsinnode = 10          # Minimum number of observations in terminal nodes
)

gbm_model <- gbm(STAT.230.1 ~ ., data = stat230grades[train_indices,2:5], distribution = gbm_params$distribution,
                 n.trees = gbm_params$n.trees, interaction.depth = gbm_params$interaction.depth,
                 shrinkage = gbm_params$shrinkage, bag.fraction = gbm_params$bag.fraction,
                 train.fraction = gbm_params$train.fraction, n.minobsinnode = gbm_params$n.minobsinnode)

# Print the summary of the trained model
print(summary(gbm_model))

# Make predictions on new data
# Assuming 'new_data' is your new dataframe for prediction
predictions <- predict(gbm_model, newdata = stat230grades[test_indices,2:5], n.trees = gbm_params$n.trees)

# Print the predictions
print(predictions)

mse <- mean((predictions - stat230grades[test_indices,2:5]$STAT.230.1)^2)
mse
## 175 mse... getting worse...
```

```{r GBM on non-NA data, eval=TRUE}
# loading in data again TRYING WITH FULL DATA
stat230grades <- studentgrades[!is.na(studentgrades$MATH.100.1)&!is.na(studentgrades$MATH.101.1)&!is.na(studentgrades$STAT.230.1)&!is.na(studentgrades$DATA.101.1),c("Student_ID","MATH.100.1","MATH.101.1","STAT.230.1","DATA.101.1")]
stat230grades
n_rows <- nrow(stat230grades)
train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing

library(gbm)

gbm_params <- list(
  distribution = "gaussian",  # Specify the distribution for regression
  n.trees = 100,               # Number of trees (iterations)
  interaction.depth = 4,       # Maximum depth of trees
  shrinkage = 0.1,             # Learning rate (shrinkage)
  bag.fraction = 0.5,          # Fraction of training data used for each tree
  train.fraction = 1.0,        # Fraction of training data used for training (1.0 for full dataset)
  n.minobsinnode = 10          # Minimum number of observations in terminal nodes
)

gbm_model <- gbm(STAT.230.1 ~ ., data = stat230grades[train_indices,2:5], distribution = gbm_params$distribution,
                 n.trees = gbm_params$n.trees, interaction.depth = gbm_params$interaction.depth,
                 shrinkage = gbm_params$shrinkage, bag.fraction = gbm_params$bag.fraction,
                 train.fraction = gbm_params$train.fraction, n.minobsinnode = gbm_params$n.minobsinnode)

# Print the summary of the trained model
print(summary(gbm_model))

# Make predictions on new data
# Assuming 'new_data' is your new dataframe for prediction
predictions <- predict(gbm_model, newdata = stat230grades[test_indices,2:5], n.trees = gbm_params$n.trees)

# Print the predictions
print(predictions)

mse <- mean((predictions - stat230grades[test_indices,2:5]$STAT.230.1)^2)
mse
## 128 mse which is a little better when you've got full data
```

```{r missForest impute into GBM, eval=TRUE}
# now, does imputing the data before GBM work better?
# preparing all student grades with stat230
stat230grades <- studentgrades[!is.na(studentgrades$STAT.230.1),c("Student_ID","MATH.100.1","MATH.101.1","DATA.101.1","STAT.230.1")]
stat230grades

library(missForest)
library(gbm)

n_rows <- nrow(stat230grades)

train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing



stat230.imputed <- missForest(stat230grades[,2:5])$ximp

gbm_params <- list(
  distribution = "gaussian",  # Specify the distribution for regression
  n.trees = 100,               # Number of trees (iterations)
  interaction.depth = 4,       # Maximum depth of trees
  shrinkage = 0.1,             # Learning rate (shrinkage)
  bag.fraction = 0.5,          # Fraction of training data used for each tree
  train.fraction = 1.0,        # Fraction of training data used for training (1.0 for full dataset)
  n.minobsinnode = 10          # Minimum number of observations in terminal nodes
)

gbm_model <- gbm(STAT.230.1 ~ ., data = stat230.imputed[train_indices,], distribution = gbm_params$distribution,
                 n.trees = gbm_params$n.trees, interaction.depth = gbm_params$interaction.depth,
                 shrinkage = gbm_params$shrinkage, bag.fraction = gbm_params$bag.fraction,
                 train.fraction = gbm_params$train.fraction, n.minobsinnode = gbm_params$n.minobsinnode)

# Print the summary of the trained model
print(summary(gbm_model))

# Make predictions on new data
# Assuming 'new_data' is your new dataframe for prediction
predictions <- predict(gbm_model, newdata = stat230.imputed[test_indices,], n.trees = gbm_params$n.trees)

# Print the predictions
print(predictions)

mse <- mean((predictions - stat230.imputed[test_indices,]$STAT.230.1)^2)
mse
## 109 mse.. better still
```

### Matrix Factorization
```{r Dataset creation for MF, eval=TRUE}
# Getting list of students wanted
studs <- studentgrades[!is.na(studentgrades$STAT.230),]$Student_ID

data <- data.frame(student = character(), course=character(), grade=double())
for(id in studs){
  for(c in 6:205){
    if(!is.na(studentgrades[studentgrades$Student_ID==id,c])){
      data <- rbind(data, list(id,colnames(studentgrades)[c],studentgrades[studentgrades$Student_ID==id,c]))
    }
  }
}

colnames(data) <- c("student","course","grade")

data <- na.omit(data)  # Remove rows with NA ratings

# Split into obj course and not
data_obj <- data[data$course=="STAT.230",]
data_non <- data[!data$course=="STAT.230",]

# Creating the testing set from obj course
n_rows <- nrow(data_obj)

train_indices <- sample(1:n_rows, 0.9 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing

data <- rbind(data_obj[test_indices,], data_obj[train_indices,],data_non)


# Factoring data
data[] <- lapply(data, function(x) {
  if (is.character(x)) {
    as.numeric(factor(x))
  } else {
    x
  }
})

obj_course <- data[1,2]
```

```{r Matrix Factorization prediction, eval=TRUE}
library(recosystem)

# Create a Reco object
r <- Reco()

# Define the training set
train_set <- data_memory(user_index = data$student[-1:-length(test_indices)], item_index = data$course[-1:-length(test_indices)], rating = data$grade[-1:-length(test_indices)])

# Train the model with ALS
r$train(train_set, opts = list(dim = 10, costp_l2 = 0.2, costq_l2 = 0.2, lrate = 0.05, niter = 20))


# Initialize the matrix to store predicted grades
predicted_grades <- data[1:length(test_indices),]
predicted_grades$grade <- NA

# Predict missing values

for(i in 1:nrow(predicted_grades)){
  predicted_grades[i,]$grade <- r$predict(data_memory(user_index = predicted_grades[i,]$student, item_index = predicted_grades[i,]$course))
}


# Print the predicted grades matrix
print(predicted_grades)


# Calculate MSE for observed (non-NA) grades
observed_indices <- which(!is.na(grades))
mse <- mean((predicted_grades$grade - data_obj[test_indices,]$grade)^2)
mse
```

### Structured Learning
```{r Structured Learning, eval=FALSE}

library(bnlearn)

suppressWarnings({
pc <- pc.stable(studentgrades[,-(1:5)], undirected = FALSE)
pc$arcs # 10 arcs

gs <- gs(studentgrades[,-(1:5)], undirected = FALSE)
gs$arcs # 10 arcs

iamb <- iamb(studentgrades[,-(1:5)])
iamb$arcs # 75 arc... some potential

hc <- tabu(studentgrades[,-(1:5)], score = "aic")
hc$arcs

mmhc <- h2pc(studentgrades[,-(1:5)])
mmhc$arcs

mmpc <- mmpc(studentgrades[,-(1:5)])
mmpc$arcs # lots of pairs but no substance
})

chow <- chow.liu(studentgrades[,-(1:5)])
chow$arcs[chow$arcs[,1]=="STAT.230"]

mmpc$arcs[mmpc$arcs[,1]=="STAT.230"]
```

### Support Vector Machines
```{r SVM model, eval=FALSE}
library(e1071)
library(missForest)

course_names <- c("COSC.121","MATH.200","MATH.221","COSC.221","COSC.211","MATH.101","COSC.222","ECON.101","COSC.111","PSYO.111","STAT.230")

grades <- studentgrades[!is.na(studentgrades$STAT.230),colnames(studentgrades) %in% course_names]

#grades.imputed <- missForest(grades)$ximp


n_rows <- nrow(grades)

train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing

xtrain <- grades[train_indices,!names(grades) %in% c("STAT.230")]
ytrain <- grades[train_indices,"STAT.230"]
xtest <- grades[test_indices,!names(grades) %in% c("STAT.230")]
ytest <- grades[test_indices,"STAT.230"]


svm_model <- svm(STAT.230~., data=grades[train_indices,])

#opt_svm <- tune(svm_model, STAT.230~., data=grades[train_indices,],ranges=list(elsilon=seq(0,1,0.1), cost=1:100))

pred_svm <- predict(svm_model, data=grades[test_indices[1],])
length(pred_svm)
pred_svm

grades.real <- grades[test_indices,"STAT.230"]

rmse <- sqrt(mean((pred_svm - grades.real)^2))
rmse
```

```{r SVM via trainControl, eval=TRUE}
library(e1071)
library(missForest)
library(kernlab)  # install if necessary using 'install.packages'
library(caret) # install if necessary using 'install.packages'

course_names <- c("COSC.121","MATH.200","MATH.221","COSC.221","COSC.211","MATH.101","COSC.222","ECON.101","COSC.111","PSYO.111","STAT.230")

grades <- studentgrades[!is.na(studentgrades$STAT.230),colnames(studentgrades) %in% course_names]
#grades <- studentgrades[!is.na(studentgrades$STAT.230),]

grades <- missForest(grades)$ximp


n_rows <- nrow(grades)

train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing

xtrain <- grades[train_indices,!names(grades) %in% c("STAT.230")]
ytrain <- grades[train_indices,"STAT.230"]
xtest <- grades[test_indices,!names(grades) %in% c("STAT.230")]
ytest <- grades[test_indices,"STAT.230"]


#To train the model we will use k-fold cross validation, with k set to 5
ctrl <- trainControl(method = "cv", number=5) 


# Create a grid of parameters to test and train the model with dimension 1
SVRGridCoarse <- expand.grid(.sigma=c(0.001, 0.01, 0.1), .C=c(10,100,1000))
SVRFitCoarse <- train(xtrain, ytrain, method="svmRadial", tuneGrid=SVRGridCoarse, trControl=ctrl, type="eps-svr")

# Display results
SVRFitCoarse

ggplot(SVRFitCoarse)

SVRFitCoarse$finalModel

yPred <- predict(SVRFitCoarse$finalModel, xtest)
```

### Recursive Feature Elimination
```{r Trying RFE... doesnt work on NA, eval=FALSE}
library("dplyr")
library("faux")
library("DataExplorer")
library("caret")
library("randomForest")

studentgrades.factor <- studentgrades %>%
  # Save categorical features as factors
  mutate_at(c("Student_ID", "Major.1", "Major.2", "Minor", "Honors"), 
            as.factor)


# Define the control using a random forest selection function
control <- rfeControl(functions = rfFuncs, # random forest
                      method = "repeatedcv", # repeated cv
                      repeats = 5, # number of repeats
                      number = 10) # number of folds

n_rows <- nrow(studentgrades.factor)

train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing

xtrain <- studentgrades.factor[train_indices,!names(studentgrades.factor) %in% c("STAT.230")]
ytrain <- studentgrades.factor[train_indices,"STAT.230"]
xtest <- studentgrades.factor[test_indices,!names(studentgrades.factor) %in% c("STAT.230")]
ytest <- studentgrades.factor[test_indices,"STAT.230"]

# Run RFE
result_rfe1 <- rfe(x = xtrain, 
                   y = ytrain, 
                   sizes = c(1:13),
                   rfeControl = control)

# Print the results
result_rfe1

# Print the selected features
predictors(result_rfe1)

# Print the results visually
ggplot(data = result_rfe1, metric = "Accuracy") + theme_bw()
ggplot(data = result_rfe1, metric = "Kappa") + theme_bw()
```

### LASSO Feature Selection
In this section there are two incomplete chunks of code. I had moved off of working on feature selection as we deemed GBMs were doing a good job at indicating which courses are the most important.
```{r LASSO feature selection, eval=FALSE}
cv_5 <- trainControl(method="cv", number=5)
studentgrades_stat230 <- studentgrades[!is.na(studentgrades$STAT.230),]
lasso <- train(STAT.230 ~., data=studentgrades_stat230, method='lasso',  trControl=cv_5, na.action = na.exclude)
```

```{r Lasso.., eval=FALSE}
library(glmnet)

cv_model <- cv.glmnet(studentgrades$STAT.230~studentgrades[,-c(1,2,3,4,5,"STAT.230")], nfolds = 10,alpha=1)
```

### Singular Value Decomposition
I had moved away from trying different modeling methods to focus on improving GBMs.................
```{r SVD, eval=FALSE}
library(svd)

trlan.eigen(studentgrades[,-(1:5)])
```



## Further work on GBM

### Summary of the Boosting Process

1. **Initialize the model** with a constant value, typically the mean of the target values for regression:

\[ 
F_0(x) = \arg\min_{c} \sum_{i=1}^{N} L(y_i, c)
\]

2. **For \(m = 1\) to \(M\) (number of boosting iterations)**:
   - Compute the residuals \(r_i^m\)
   - For squared error loss, this simplifies to:
\[
r_i^m = y_i - F_{m-1}(x_i)
\]
   - Fit a base learner \(h_m(x)\) to the residuals.
   - Update the model via gradient decent:

\[
F_{m}(x) = F_{m-1}(x) + \nu h_m(x)
\]

3. **Final prediction** is the sum of all base learners:

\[
\hat{y} = F_M(x) = \sum_{m=1}^{M} \nu h_m(x)
\]


- What we are controlling and changing:
    - Boosting iterations (\texttt{ntrees}): variable...
    - Learning rate (\texttt{shrinkage} parameter): 0.05
    - Loss function distribution: Gaussian


### Data Preperation
```{r GBM data prep, eval=TRUE}
# Identifying the course of interest
COI <- "COSC.221"
coursegrades <- studentgrades_prof[!is.na(studentgrades_prof[,COI]),-c(1,3,5)]

# remove all grades < 50%
coursegrades <- coursegrades[coursegrades$COSC.221 >= 40, ]
# coursegrades <- coursegrades[coursegrades$COSC.221 <= 80, ]

# factoring student majors
coursegrades$Major.1 <- factor(coursegrades$Major.1)
# factoring student minors
coursegrades$Minor <- factor(coursegrades$Minor)


# removing all students who don't meet course pre reqs DATA 101, COSC 221
coursegrades <- coursegrades[!is.na(coursegrades$MATH.101) | !is.na(coursegrades$MATH.103) | !is.na(coursegrades$MATH.142), ]

# coursegrades <- coursegrades[!is.na(coursegrades$MATH.101), ]



# dropping columns that are very sparse (pct % are NA)
pct <- 0.8
courses <- numeric(0)
for (i in 1:ncol(coursegrades)) {
  if(is.na(coursegrades[,i]) |> sum()  > nrow(coursegrades)*pct){
    courses <- c(courses,i)
  }
}

coursegrades <- coursegrades[,-courses]





# Removing all course columns of higher years
YOI <- as.integer(substr(strsplit(COI, split = ".", fixed = TRUE)[[1]][2],1,1))

column_names <- colnames(coursegrades)

# Extract digits after the period in column names
column_digits <- as.integer(sub("^[^.]+\\.([0-9]).*", "\\1", column_names))

# Find columns with digits not matching the selected course year
cols_to_keep <- column_names[column_digits <= YOI]

# All columns in the same year or below
coursegrades <- coursegrades[, colnames(coursegrades) %in% cols_to_keep]

# display data to be used
head(coursegrades)
```

### Analysis
```{r finding ideal number of GBM tree graphs to use, eval=FALSE}
library(gbm)

gbm_params <- list(
  distribution = "gaussian",  # Specify the distribution for regression
  n.trees = 10000,               # Number of trees (iterations)
  interaction.depth = 3,       # Maximum depth of trees
  shrinkage = 0.001,            # Learning rate (shrinkage)
  bag.fraction = 0.5,          # Fraction of training data used for each tree
  train.fraction = 1.0,        # Fraction of training data used for training (1.0 for full dataset)
  n.minobsinnode = 5          # Minimum number of observations in terminal nodes
)

# Running model first time on base params
gbm_model <- gbm(MATH.200 ~ ., data = coursegrades, distribution = gbm_params$distribution,
                 n.trees = gbm_params$n.trees, interaction.depth = gbm_params$interaction.depth,
                 shrinkage = gbm_params$shrinkage, bag.fraction = gbm_params$bag.fraction,
                 train.fraction = gbm_params$train.fraction, n.minobsinnode = gbm_params$n.minobsinnode, cv.folds = 5)


print(gbm.perf(gbm_model, method="cv"))
print(gbm.perf(gbm_model, method="OOB"))
```

```{r GBM model training, eval=TRUE}
set.seed(5934)
n_rows <- nrow(coursegrades)
train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing

library(gbm)

gbm_params <- list(
  distribution = "gaussian",  # Specify the distribution for regression
  n.trees = 8000,               # Number of trees (iterations)
  interaction.depth = 3,       # Maximum depth of trees
  shrinkage = 0.005,            # Learning rate (shrinkage)
  bag.fraction = 0.5,          # Fraction of training data used for each tree
  train.fraction = 1.0,        # Fraction of training data used for training (1.0 for full dataset)
  n.minobsinnode = 5          # Minimum number of observations in terminal nodes
)

# Running model first time on base params
gbm_model <- gbm(COSC.221 ~ ., data = coursegrades, distribution = gbm_params$distribution,
                 n.trees = gbm_params$n.trees, interaction.depth = gbm_params$interaction.depth,
                 shrinkage = gbm_params$shrinkage, bag.fraction = gbm_params$bag.fraction,
                 train.fraction = gbm_params$train.fraction, n.minobsinnode = gbm_params$n.minobsinnode, cv.folds = 5)

# saving optimal # of trees
ntrees <- gbm.perf(gbm_model,method="cv")[1]



# Running model a second time with optimal # of trees
gbm_model <- gbm(COSC.221 ~ ., data = coursegrades[train_indices,], distribution = gbm_params$distribution,
                 n.trees = ntrees, interaction.depth = gbm_params$interaction.depth,
                 shrinkage = gbm_params$shrinkage, bag.fraction = gbm_params$bag.fraction,
                 train.fraction = gbm_params$train.fraction, n.minobsinnode = gbm_params$n.minobsinnode, cv.folds = 5)

# Print the summary of the trained model
print(summary(gbm_model))

# Make predictions on new data
predictions <- predict(gbm_model, newdata = coursegrades[test_indices,], n.trees = ntrees)

rmse <- sqrt(mean((predictions - coursegrades[test_indices,COI])^2))
rmse
```


### Hyperparameter Training
```{r gridSearch on GBM, eval=FALSE}
library(caret)
library(tidyverse)

train_control = trainControl(method = "cv", number = 5, search = "grid")

gbmGrid <-  expand.grid(
  # distribution = "gaussian",  # Specify the distribution for regression
  n.trees = c(200,500,1000,1500,2000),               # Number of trees (iterations)
  interaction.depth = c(3:7),       # Maximum depth of trees
  shrinkage = c(0.025,0.01,0.005,0.0025,0.001),           # Learning rate (shrinkage)
  # bag.fraction = 0.5,          # Fraction of training data used for each tree
  # train.fraction = 1.0,        # Fraction of training data used for training (1.0 for full dataset)
  n.minobsinnode = c(5,8,10,12,15)          # Minimum number of observations in terminal nodes
)

# training a Gboost Regression tree model while tuning parameters
model = train(STAT.230~., data = coursegrades[train_indices], method = "gbm", trControl = train_control, tuneGrid = gbmGrid, na.action = na.pass)

# summarising the results
print(model)

# Make predictions on new data
# predictions <- predict(model$bestTune, newdata = coursegrades[test_indices,], n.trees = ntrees)
# 
# rmse <- sqrt(mean((predictions - coursegrades[test_indices,COI])^2))
# rmse
```

### Adding Error Bars
```{r adding error bars... que?}
## calculating size of error bars
errors <- abs(predictions - actual)
error_bars <- sd(errors)




## plotting graph and error bars
plot(actual, predictions, 
     xlab = "Actual Grades", ylab = "Predicted Grades",
     main = "Predicted vs Actual Grades with Error Bars", xlim = c(0,100), ylim = c(0,100),pch = 16)

# Add error bars
arrows(actual, predictions - error_bars, 
       actual, predictions + error_bars, 
       angle = 90, code = 3, length = 0.1, col = 1:length(predictions))

abline(0, 1, col = "red")
```

```{r quantile gbm error bars, eval=TRUE}
## training two more gbms using quantile ranges as the prediction interval

gbm_params <- list(
  distribution = list(name = "quantile", alpha = 0.025),  # Specify the distribution for regression
  n.trees = 8000,               # Number of trees (iterations)
  interaction.depth = 4,       # Maximum depth of trees
  shrinkage = 0.001,            # Learning rate (shrinkage)
  bag.fraction = 0.5,          # Fraction of training data used for each tree
  train.fraction = 1.0,        # Fraction of training data used for training (1.0 for full dataset)
  n.minobsinnode = 5          # Minimum number of observations in terminal nodes
)

# Running model first time on base params
gbm_model <- gbm(STAT.230 ~ ., data = coursegrades[train_indices,], distribution = gbm_params$distribution,
                 n.trees = gbm_params$n.trees, interaction.depth = gbm_params$interaction.depth,
                 shrinkage = gbm_params$shrinkage, bag.fraction = gbm_params$bag.fraction,
                 train.fraction = gbm_params$train.fraction, n.minobsinnode = gbm_params$n.minobsinnode, cv.folds = 5)

LB_predictions <- predict(gbm_model, newdata = coursegrades[test_indices,], n.trees = ntrees)


gbm_params <- list(
  distribution = list(name = "quantile", alpha = 0.975),  # Specify the distribution for regression
  n.trees = 8000,               # Number of trees (iterations)
  interaction.depth = 4,       # Maximum depth of trees
  shrinkage = 0.001,            # Learning rate (shrinkage)
  bag.fraction = 0.5,          # Fraction of training data used for each tree
  train.fraction = 1.0,        # Fraction of training data used for training (1.0 for full dataset)
  n.minobsinnode = 5          # Minimum number of observations in terminal nodes
)

# Running model first time on base params
gbm_model <- gbm(STAT.230 ~ ., data = coursegrades[train_indices,], distribution = gbm_params$distribution,
                 n.trees = gbm_params$n.trees, interaction.depth = gbm_params$interaction.depth,
                 shrinkage = gbm_params$shrinkage, bag.fraction = gbm_params$bag.fraction,
                 train.fraction = gbm_params$train.fraction, n.minobsinnode = gbm_params$n.minobsinnode, cv.folds = 5)

UB_predictions <- predict(gbm_model, newdata = coursegrades[test_indices,], n.trees = ntrees)

## plotting graph and error bars
plot(actual, predictions, 
     xlab = "Actual Grades", ylab = "Predicted Grades",
     main = "Predicted vs Actual Grades with Error Bars", xlim = c(00,100), ylim = c(0,100),pch = 16)

# Add error bars
arrows(actual, LB_predictions, 
       actual, UB_predictions, 
       angle = 90, code = 3, length = 0.1, col = 1:length(predictions))

abline(0, 1, col = "red")
```

```{r bootstrap gbm error bars, eval=FALSE}
# bootstrapping the model x times
n_iterations = 50  # Number of bootstrapped models
boot_preds = numeric(0)


library(gbm)

gbm_params <- list(
  distribution = "gaussian",  # Specify the distribution for regression
  n.trees = 6000,               # Number of trees (iterations)
  interaction.depth = 3,       # Maximum depth of trees
  shrinkage = 0.001,            # Learning rate (shrinkage)
  bag.fraction = 0.5,          # Fraction of training data used for each tree
  train.fraction = 1.0,        # Fraction of training data used for training (1.0 for full dataset)
  n.minobsinnode = 5          # Minimum number of observations in terminal nodes
)


for(i in 1:n_iterations){
  # Create a bootstrapped dataset
  set.seed(100+i)
  
  n_rows <- nrow(coursegrades)
  train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
  test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing
    
  gbm_model <- gbm(STAT.230 ~ ., data = coursegrades[train_indices,], distribution = gbm_params$distribution,
                 n.trees = gbm_params$n.trees, interaction.depth = gbm_params$interaction.depth,
                 shrinkage = gbm_params$shrinkage, bag.fraction = gbm_params$bag.fraction,
                 train.fraction = gbm_params$train.fraction, n.minobsinnode = gbm_params$n.minobsinnode, cv.folds = 5)

  
  # Predict on test data
  preds <- predict(gbm_model, newdata = coursegrades[test_indices,], n.trees = ntrees)
  boot_preds <- append(boot_preds, preds)
  
}

# Convert predictions to a NumPy array
#predictions

# Calculate the mean and standard deviation of the predictions
mean_preds <- mean(boot_preds)
std_preds <- sd(boot_preds)

# Confidence interval on average grade of STAT 230
lower_bound <- mean_preds - 1.96 * std_preds
upper_bound <- mean_preds + 1.96 * std_preds


## plotting graph and error bars made from bootstrapping predictions from many different models
UB_predictions <- predictions + 1.96 * std_preds
LB_predictions <- predictions - 1.96 * std_preds


plot(actual, predictions, 
     xlab = "Actual Grades", ylab = "Predicted Grades",
     main = "Predicted vs Actual Grades with Error Bars", xlim = c(00,100), ylim = c(0,100),pch = 16)

# Add error bars
arrows(actual, LB_predictions, 
       actual, UB_predictions, 
       angle = 90, code = 3, length = 0.1, col = 1:length(predictions))

abline(0, 1, col = "red")
```


### Variable selection
This variable selection technique was taken from a **paper** with some modifications to see if removing variables improves the model
```{r GBM recursive variable selection on prof data}

set.seed(5934)
n_rows <- nrow(coursegrades)
train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing

library(gbm)

gbm_params <- list(
  distribution = "gaussian",  # Specify the distribution for regression
  n.trees = 8000,               # Number of trees (iterations)
  interaction.depth = 3,       # Maximum depth of trees
  shrinkage = 0.001,            # Learning rate (shrinkage)
  bag.fraction = 0.5,          # Fraction of training data used for each tree
  train.fraction = 1.0,        # Fraction of training data used for training (1.0 for full dataset)
  n.minobsinnode = 5          # Minimum number of observations in terminal nodes
)

# Running model first time on base params
gbm_model <- gbm(STAT.230 ~ ., data = coursegrades, distribution = gbm_params$distribution,
                 n.trees = gbm_params$n.trees, interaction.depth = gbm_params$interaction.depth,
                 shrinkage = gbm_params$shrinkage, bag.fraction = gbm_params$bag.fraction,
                 train.fraction = gbm_params$train.fraction, n.minobsinnode = gbm_params$n.minobsinnode, cv.folds = 5)

# saving optimal # of trees
ntrees <- gbm.perf(gbm_model,method="cv")[1]



# Running model a second time with optimal # of trees
gbm_model <- gbm(STAT.230 ~ ., data = coursegrades[train_indices,], distribution = gbm_params$distribution,
                 n.trees = ntrees, interaction.depth = gbm_params$interaction.depth,
                 shrinkage = gbm_params$shrinkage, bag.fraction = gbm_params$bag.fraction,
                 train.fraction = gbm_params$train.fraction, n.minobsinnode = gbm_params$n.minobsinnode, cv.folds = 5)


# Make predictions on new data
predictions <- predict(gbm_model, newdata = coursegrades[test_indices,], n.trees = ntrees)

rmse <- sqrt(mean((predictions - coursegrades[test_indices,COI])^2))
rmse

# making df to save columns removed and rmse
model_perf <- data.frame(RMSE = rmse, col1 = NA, col2 = NA)








# creating a temp coursegrades which we will modify
temp_coursegrades <- coursegrades

# main loop to filter variables
for(loop in 1:floor((ncol(coursegrades)-3)/2)){
  
  # getting relative influence of variables
  col_inf <- matrix(relative.influence(gbm_model))
  col_inf_names <- gbm_model$var.names
  
  rel_inf <- data.frame(influence = col_inf, column = col_inf_names)
  
  rel_inf <- rel_inf[order(rel_inf$influence, decreasing = FALSE),]
  
  
  # find columns to remove
  cols_to_remove <- rel_inf[c(1,2),2]
  for(i in 1:2){
    col <- grep(cols_to_remove[i], colnames(temp_coursegrades))[1]
    temp_coursegrades <- temp_coursegrades[,-col]
  }
  
  set.seed(1234)
  n_rows <- nrow(temp_coursegrades)
  train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
  test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing
  
  
  
  # Running model first time on base params
  gbm_model <- gbm(STAT.230 ~ ., data = temp_coursegrades, distribution = gbm_params$distribution,
                 n.trees = gbm_params$n.trees, interaction.depth = gbm_params$interaction.depth,
                 shrinkage = gbm_params$shrinkage, bag.fraction = gbm_params$bag.fraction,
                 train.fraction = gbm_params$train.fraction, n.minobsinnode = gbm_params$n.minobsinnode, cv.folds = 10)

  # saving optimal # of trees
  ntrees <- gbm.perf(gbm_model,method="cv")[1]



  # Running model a second time with optimal # of trees
  gbm_model <- gbm(STAT.230 ~ ., data = temp_coursegrades[train_indices,], distribution = gbm_params$distribution,
                 n.trees = ntrees, interaction.depth = gbm_params$interaction.depth,
                 shrinkage = gbm_params$shrinkage, bag.fraction = gbm_params$bag.fraction,
                 train.fraction = gbm_params$train.fraction, n.minobsinnode = gbm_params$n.minobsinnode, cv.folds = 10)
  
  
  print(summary(gbm_model))
  
  # Make predictions on new data
  predictions <- predict(gbm_model, newdata = coursegrades[test_indices,], n.trees = ntrees)

  rmse <- sqrt(mean((predictions - coursegrades[test_indices,COI])^2))
  
  model_perf <- rbind(model_perf, c(rmse, cols_to_remove))
  
}

```

## Extreme Gradient Boosting
```{r extreme gradient boosting, eval=FALSE}
library(xgboost)

set.seed(5934)
# set.seed(555)
n_rows <- nrow(coursegrades)
train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing

## xgbm data setup
train_data <- xgb.DMatrix(as.matrix(coursegrades[train_indices,!names(coursegrades) %in% c("STAT.230")]), label = coursegrades[train_indices,"STAT.230"])
test_data <- xgb.DMatrix(as.matrix(coursegrades[test_indices,!names(coursegrades) %in% c("STAT.230")]), label = coursegrades[test_indices,"STAT.230"])



watchlist = list(train=train_data, test=test_data)

xgbm_model <- xgb.train(data=train_data, max.depth=4, eta=0.01, nthread = 2, nrounds=1000, lambda = 0, booster = "gbtree", subsample = 0.5, tree_method = "auto", watchlist=watchlist, objective = "reg:squarederror", verbose = 0, early_stopping_rounds = 10, colsample_bytree = 0.5)

# Print the summary of the trained model
summary(xgbm_model)


# Make predictions on new data
predictions <- predict(xgbm_model, test_data)

rmse <- sqrt(mean((predictions - coursegrades[test_indices,COI])^2))
rmse
```

```{r gridSearch on xGBM, eval=FALSE}
library(caret)
library(tidyverse)

searchGridSubCol <- expand.grid(subsample = c(0.5, 0.65, 0.8), 
                                colsample_bytree = c(0.5, 0.75, 1),
                                max_depth = c(1, 2),
                                lambda = c(0,1,2), 
                                alpha = c(0,1,2),
                                min_child = c(1,3),
                                eta = c(0.05, 0.01, 0.005, 0.001)
)

ntrees <- 10000

system.time(
rmseErrorsHyperparameters <- apply(searchGridSubCol, 1, function(parameterList){
  
  #Extract Parameters to test
  currentSubsampleRate <- parameterList[["subsample"]]
  currentColsampleRate <- parameterList[["colsample_bytree"]]
  currentDepth <- parameterList[["max_depth"]]
  currentEta <- parameterList[["eta"]]
  currentLambda <- parameterList[["lambda"]]
  currentAlpha <- parameterList[["alpha"]]
  currentMinChild <- parameterList[["min_child"]]
  xgboostModelCV <- xgb.cv(data =  train_data, nrounds = ntrees, nfold = 5, showsd = TRUE, 
                       metrics = "rmse", verbose = TRUE, "eval_metric" = "rmse",
                     "objective" = "reg:linear", "max.depth" = currentDepth, "eta" = currentEta,                               
                     "subsample" = currentSubsampleRate, "colsample_bytree" = currentColsampleRate
                      , print_every_n = 10, "lambda" = currentLambda, "alpha" = currentAlpha, "min_child" = currentMinChild, booster = "gbtree",
                     early_stopping_rounds = 10)
  
  xvalidationScores <- as.data.frame(xgboostModelCV$evaluation_log)
  rmse <- tail(xvalidationScores$test_rmse_mean, 1)
  trmse <- tail(xvalidationScores$train_rmse_mean,1)
  output <- return(c(rmse, trmse, currentSubsampleRate, currentColsampleRate, currentDepth, currentEta, currentMinChild))}))


# Showing hyperparameter results
xgb_hyperparams <- data.frame(t(rmseErrorsHyperparameters))
xgb_hyperparams$lambda <- searchGridSubCol$lambda
xgb_hyperparams$alpha <- searchGridSubCol$alpha

colnames(xgb_hyperparams) <- c("rmse", "trmse", "subsample", "colsample_bytree", "max_depth", "eta", "min_child", "lambda", "alpha")

xgb_hyperparams[order(xgb_hyperparams$rmse),]
```

```{r adding bootstrapped xGBM error bars, eval=FALSE}
# bootstrapping the model x times 

n_iterations = 100  # Number of bootstrapped models
predictions = numeric(0)

for(i in 1:n_iterations){
  # Create a bootstrapped dataset
  set.seed(100+i)
  
  n_rows <- nrow(coursegrades)
  train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
  test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing
    
  # Train an XGBoost model
  train_data <- xgb.DMatrix(as.matrix(coursegrades[train_indices,!names(coursegrades) %in% c("STAT.230")]), label = coursegrades[train_indices,"STAT.230"])
  test_data <- xgb.DMatrix(as.matrix(coursegrades[test_indices,!names(coursegrades) %in% c("STAT.230")]), label = coursegrades[test_indices,"STAT.230"])

  watchlist = list(train=train_data, test=test_data)

  xgbm_model <- xgb.train(data=train_data, max.depth=4, eta=0.01, nthread = 2, nrounds=1000, lambda = 0, booster = "gbtree", subsample = 0.5, tree_method = "auto", watchlist=watchlist, objective = "reg:squarederror", verbose = 0, early_stopping_rounds = 10, colsample_bytree = 0.5)
    
  # Predict on test data
  preds <- predict(xgbm_model, test_data)
  predictions <- append(predictions, preds)
  
  sprintf("%s done", i)
}

# Convert predictions to a NumPy array
#predictions

# Calculate the mean and standard deviation of the predictions
mean_preds = mean(predictions)
std_preds = sd(predictions)


## plotting graph and error bars made from bootstrapping predictions from many different models
UB_predictions <- predictions + 1.96 * std_preds
LB_predictions <- predictions - 1.96 * std_preds


plot(actual, predictions, 
     xlab = "Actual Grades", ylab = "Predicted Grades",
     main = "Predicted vs Actual Grades with Error Bars", xlim = c(00,100), ylim = c(0,100),pch = 16)

# Add error bars
arrows(actual, LB_predictions, 
       actual, UB_predictions, 
       angle = 90, code = 3, length = 0.1, col = 1:length(predictions))

abline(0, 1, col = "red")
```


## Main Plots Used
### Predicted grades vs Actual grades
```{r predicted grades vs actual grades, eval=TRUE}
actual <- coursegrades[test_indices,]$STAT.230
plot(actual, predictions, xlab = "Actual Grades", ylab = "Predicted Grades", 
     main = "Predicted vs Actual Grades", pch = 16, col = "blue", xlim = c(0,100), ylim = c(0,100))

# this line represents 'perfect prediction' where actual grades = predicted grades
abline(0, 1, col = "red")

# creating and drawing line of best fit on the predicted data
line.lm <- lm(predictions~actual)
abline(line.lm, col = "green")
```

### Residuals
```{r residuals, eval=TRUE}
residuals <- actual - predictions
plot(predictions, residuals, xlab = "Predicted Grades", ylab = "Residuals", 
     main = "Residual Plot", pch = 16, col = "blue")
abline(h = 0, col = "red")

line.lm <- lm(residuals~predictions)
abline(line.lm, col = "green")
```

### Q-Q Plots
```{r qq plots, eval=TRUE}
qqnorm(residuals, main = "Normal Q-Q Plot of Residuals")
qqline(residuals, col = "red")
```

### Heatmap
```{r conf matrix and heat map, eval=TRUE}
library(ggplot2)
library(caret)

# Define breaks for intervals of 5
breaks <- seq(0, 100, by = 5)

# Create labels for the intervals
labels <- paste(breaks[-length(breaks)], breaks[-1], sep = "-")

actual_fac <- cut(actual, breaks = breaks, labels = labels, right = TRUE, include.lowest = TRUE)
pred_fac <- cut(predictions, breaks = breaks, labels = labels, right = TRUE, include.lowest = TRUE)

confusion_matrix <- table(actual_fac, pred_fac)


confusion_matrix <- confusionMatrix(confusion_matrix)
# Print the confusion matrix
# confusion_matrix

# Print recall for each class
rec <- confusion_matrix$byClass[, "Recall"]
prec <- confusion_matrix$byClass[, "Precision"]
f1_score <- 2*prec*rec/(prec+rec)

confusion_matrix$Freq[is.na(confusion_matrix$Freq)] <- 0

# Create the heat map
ggplot(as.data.frame(confusion_matrix$table), aes(x = actual_fac, y = pred_fac, fill = Freq)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "white", high = "red") +
  labs(x = "Actual Grades", y = "Predicted Grades", fill = "Frequency") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  geom_tile(data = subset(as.data.frame(confusion_matrix$table), actual_fac == pred_fac),
            aes(fill = Freq), color = "black")
```

```{r Heatmap on prediction letter grades, eval=TRUE}
library(caret)
library(ggplot2)

# Function to assign letter grades based on numeric ranges
assign_grades <- function(scores) {
  # Define the breaks for the numeric ranges
  breaks <- c(-Inf, 49, 54, 59, 63, 67, 71, 75, 79, 84, 89, 100)
  
  # Define the corresponding labels for each range
  labels <- c("F", "D", "C-", "C", "C+", "B-", "B", "B+", "A-", "A", "A+")
  
  # Use the cut function to assign labels based on the breaks
  grades <- cut(scores, breaks = breaks, labels = labels, right = TRUE)
  
  return(grades)
}


predictions_letter <- assign_grades(predictions)
actual_letter <- assign_grades(actual)

# displaying confusion matrix
confusionMatrix(predictions_letter, actual_letter)


confusion_matrix <- table(actual_letter, predictions_letter)
confusion_matrix <- confusionMatrix(confusion_matrix)

# Creating and displaying heat map
ggplot(as.data.frame(confusion_matrix$table), aes(x = actual_letter, y = predictions_letter, fill = Freq)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "white", high = "red") +
  labs(x = "Actual Grades", y = "Predicted Grades", fill = "Frequency") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  geom_tile(data = subset(as.data.frame(confusion_matrix$table), actual_letter == predictions_letter),
            aes(fill = Freq), color = "black")
```

## Data Variations on GBM
This chunk will use students grades of the current year (eg. second year uses STAT.230 and COSC.221) to train the GBM model. However, the test set will have grades from the current year removed (eg. won't use COSC.221 as a predictor). In hindsight this isn't a great idea when using GBMs as the decision trees used won't be configured for the subset of courses used.
```{r, eval=FALSE}
## sets all courses of equal or higher level to NA before prediction, but after training the model
set.seed(5934)
# time to remove all future year courses from prediction
COI <- "STAT.230.1"
coursegrades <- studentgrades[!is.na(studentgrades[,COI]),-1:-5]

# figuring out the year level of each course...
YOI <- as.integer(substr(strsplit(COI, split = ".", fixed = TRUE)[[1]][2],1,1))

column_names <- colnames(coursegrades)

# Extract digits after the period in column names
column_digits <- as.integer(sub("^[^.]+\\.([0-9]).*", "\\1", column_names))

# Find columns with digits not matching the selected course year
cols_to_keep <- column_names[column_digits <= YOI]
cols_to_keep <- append(cols_to_keep, COI)

# All columns in the same year or below
coursegrades <- coursegrades[, colnames(coursegrades) %in% cols_to_keep]

# extras/ to do next
grade_counts <- colSums(!is.na(coursegrades))
# Subset columns with less than 10 grades
sparse_cols <- names(grade_counts[grade_counts <= 5])

# Need to exclude future attempts at the course, but not past
## eg. PSYO.380.1 shouldn't use 380.2 as a predictor, but 380.2 can use 380.1
if(length(strsplit(COI, split = ".", fixed = TRUE)[[1]]) == 3){
  cname <- strsplit(COI, split = ".", fixed = TRUE)[[1]][1]
  cnum <- strsplit(COI, split = ".", fixed = TRUE)[[1]][2]
  crep <- as.integer(strsplit(COI, split = ".", fixed = TRUE)[[1]][3])
  # remove all future instances of course (if they exist)
  for(i in 1:length(column_names)){
    if(strsplit(column_names[i], split = ".", fixed = TRUE)[[1]][1] == cname & strsplit(column_names[i], split = ".", fixed = TRUE)[[1]][2] == cnum & as.integer(strsplit(column_names[i], split = ".", fixed = TRUE)[[1]][3]) > crep){
      sparse_cols <- append(sparse_cols, column_names[i])
    }
  }
}

# Subset the dataframe to include only courses used to predict on
coursegrades <- coursegrades[, -which(names(coursegrades) %in% sparse_cols)]

set.seed(5934)
n_rows <- nrow(coursegrades)
train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing

cols_to_na <- column_names[column_digits == YOI] #### ADD BACK COURSE OF INTEREST!!!!!!!
cols_to_na <- cols_to_na[!cols_to_na == COI]
coursegrades[test_indices, which(names(coursegrades) %in% cols_to_na)] <- NA

library(gbm)

gbm_params <- list(
  distribution = "gaussian",  # Specify the distribution for regression
  n.trees = 100,               # Number of trees (iterations)
  interaction.depth = 4,       # Maximum depth of trees
  shrinkage = 0.1,             # Learning rate (shrinkage)
  bag.fraction = 0.5,          # Fraction of training data used for each tree
  train.fraction = 1.0,        # Fraction of training data used for training (1.0 for full dataset)
  n.minobsinnode = 10          # Minimum number of observations in terminal nodes
)



gbm_model <- gbm(STAT.230.1 ~ ., data = coursegrades[train_indices,], distribution = gbm_params$distribution,
                 n.trees = gbm_params$n.trees, interaction.depth = gbm_params$interaction.depth,
                 shrinkage = gbm_params$shrinkage, bag.fraction = gbm_params$bag.fraction,
                 train.fraction = gbm_params$train.fraction, n.minobsinnode = gbm_params$n.minobsinnode, cv.folds = 10)

# Print the summary of the trained model
print(summary(gbm_model))

# Make predictions on new data
# Assuming 'new_data' is your new dataframe for prediction
predictions <- predict(gbm_model, newdata = coursegrades[test_indices,], n.trees = gbm_params$n.trees)

# Print the predictions
predictions

mse <- mean((predictions - coursegrades[test_indices,COI])^2)
mse

```




```{r}

```
# Current Line GBM: 470
It starts to get into the section which uses only the students most recent grade...
SHould i make a new section for these things?  ... probably

# 