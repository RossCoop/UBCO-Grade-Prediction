---
title: "EDA and Model Testing"
author: "Ross Cooper 54907605"
date: "2024-05-06"
output: html_document
---

```{r}
df <- read.csv("..\\UBCO-Grade-Prediction-data\\student-data.csv")

df_clean <- df[,c(1,2,3,4,5,6,7,8,9,10,11,12,13,15,16,17)]
#df_clean <- na.omit(df_clean)
# Do some cleaning on chr columns
df_clean$STUD_NO_ANONYMOUS <- trimws(df_clean$STUD_NO_ANONYMOUS)
df_clean$CRS_DPT_CD <- trimws(df_clean$CRS_DPT_CD)
df_clean$HDR_CRS_LTTR_GRD <- trimws(df_clean$HDR_CRS_LTTR_GRD)
df_clean$CURR_SPEC_PRIM_PGM_TYPE_1 <- trimws(df_clean$CURR_SPEC_PRIM_PGM_TYPE_1)
df_clean$CURR_SPEC_PRIM_SUBJECT_1 <- trimws(df_clean$CURR_SPEC_PRIM_SUBJECT_1)
df_clean$CURR_SPEC_PRIM_PGM_TYPE_2 <- trimws(df_clean$CURR_SPEC_PRIM_PGM_TYPE_2)
df_clean$CURR_SPEC_PRIM_SUBJECT_2 <- trimws(df_clean$CURR_SPEC_PRIM_SUBJECT_2)
df_clean$CURR_SPEC_SECN_PGM_TYPE_1 <- trimws(df_clean$CURR_SPEC_SECN_PGM_TYPE_1)
df_clean$CURR_SPEC_SECN_SUBJECT_1 <- trimws(df_clean$CURR_SPEC_SECN_SUBJECT_1)
df_clean$CURR_SPEC_SECN_PGM_TYPE_2 <- trimws(df_clean$CURR_SPEC_SECN_PGM_TYPE_2)
df_clean$CURR_SPEC_SECN_SUBJECT_2 <- trimws(df_clean$CURR_SPEC_SECN_SUBJECT_2)
df_clean$DEGR_PGM_CD <- trimws(df_clean$DEGR_PGM_CD)


# Factor grades column
grades <-
  c("A+", "A", "A-", "B+", "B", "B-", "C+", "C", "C-", "D", "F")
df_clean$HDR_CRS_LTTR_GRD <-
  factor(df_clean$HDR_CRS_LTTR_GRD, levels = grades)

# Create course code column
df_clean$COURSE_CODE <- paste(df_clean$CRS_DPT_CD, df_clean$CRS_NO, sep = ".")
df_clean <- df_clean[,-(12:13)]
# Removing all withdrawl grades
df_clean <- df_clean[df_clean$HDR_CRS_PCT_GRD < 999,]
# Changing all withdrawls (999.9) to -1 to ensure they're kept in the data
#df_clean$HDR_CRS_PCT_GRD[df_clean$HDR_CRS_PCT_GRD == 999.9] <- -1



# Removing 2023 grades (not included) [also does nothing bc ^ cleans it out]
df_clean <- subset(df_clean, SEC_SES_YR < 2022.5)

# Subsetting only BSc students
df_bsc <- df_clean
#df_bsc <- df_clean[df_clean$DEGR_PGM_CD=="BSC-O",]


df_bsc
```

```{r}
# Determining how many bsc students took each course
unique(df_clean$COURSE_CODE)|>length()
courses_taken_bsc <- table(df_bsc$COURSE_CODE)


#sorted_courses_taken_bsc <- sort(courses_taken_bsc, decreasing = TRUE)[1:200]
sorted_courses_taken_bsc <- sort(courses_taken_bsc, decreasing = TRUE)
sorted_courses_taken_bsc

barplot(sorted_courses_taken_bsc)
# saving course names
course_names <- dimnames(sorted_courses_taken_bsc)[[1]]

# Subsetting on only courses which are taken the most times ("relevant courses")
df_bsc_relevant_courses <- df_bsc[df_bsc$COURSE_CODE %in% course_names, ]

# Getting a list of all student ids which took relevant courses
uniqueids <- unique(df_bsc_relevant_courses$STUD_NO_ANONYMOUS)
```



```{r}
# checking individual student ids
#df_clean[df_clean$STUD_NO_ANONYMOUS=="18AAED88A88707993EE1AF22933D1CE3",]


```


```{r}
# finding student who've taken a course more than once
duplicate_rows <- df_bsc_relevant_courses[duplicated(df_bsc_relevant_courses[c("STUD_NO_ANONYMOUS", "COURSE_CODE")]) | duplicated(df_bsc_relevant_courses[c("STUD_NO_ANONYMOUS", "COURSE_CODE")], fromLast = TRUE), ]
duplicate_rows[c(1,15,12,13)]

# Count occurrences of each course for each student
course_counts <- table(duplicate_rows$STUD_NO_ANONYMOUS, duplicate_rows$COURSE_CODE)

# Find the maximum number of times each course was taken by any student
max_repeats <- apply(course_counts, 2, max)

# Combine course names with corresponding maximum counts
max_course_counts_df <- data.frame(COURSE_CODE = names(max_repeats), max_repeats)
#sum(max_course_counts_df$max_repeats)
```

```{r}
# Creating a new list of course column names
## eg. Math.101.1, Math.101.2...

## want a list of course names with the .1 .2 .3
# groups: Non-Repeats, Repeats
# Non-repeats
non_rep_courses <- setdiff(course_names,max_course_counts_df$COURSE_CODE)

# Repeats
# Modify course names for repeated courses
rep_courses <- c()
for (i in 1:nrow(max_course_counts_df)) {
  for (j in 1:max_course_counts_df[i,2]) {
    rep_courses <- append(rep_courses, paste0(max_course_counts_df[i,1], ".", j))
  }
}

course_names_dups <- append(non_rep_courses, rep_courses)
```


```{r}
# Finding student majors and minors
### WARNING: no 2023 data yet which may contain updates to major/minors


# looking through/ getting last row of each student
library(dplyr)

# Assuming your dataframe is called 'df'

# Group by student_id and get the last row of each group
last_rows <- df_bsc_relevant_courses %>%
  group_by(STUD_NO_ANONYMOUS) %>%
  slice(n())


# Create a data frame with NA values and course column names
new_columns <- data.frame(matrix(NA, nrow = nrow(last_rows), ncol = 4))


# Add course name columns to existing data frame
student_mm <- cbind(last_rows[,1], new_columns)
colnames(student_mm) <- c("StudentID", "Major.1", "Major.2", "Minor", "Honors")
student_mm$Honors <- FALSE

for(i in 1:nrow(last_rows)){
  # If MAJ is in column 1, major.1 is that subject
  if(last_rows[i,]$CURR_SPEC_PRIM_PGM_TYPE_1=="MAJ"){
    student_mm[i,]$Major.1 <- last_rows[i,]$CURR_SPEC_PRIM_SUBJECT_1
  }
  
  # if MAJ is in col 2, check if major.1 is occupied and place it in maj.1 or maj.2
  if(last_rows[i,]$CURR_SPEC_PRIM_PGM_TYPE_2=="MAJ" & is.na(student_mm[i,]$Major.1)){
    student_mm[i,]$Major.1 <- last_rows[i,]$CURR_SPEC_PRIM_SUBJECT_2
  } else if (last_rows[i,]$CURR_SPEC_PRIM_PGM_TYPE_2=="MAJ"){
    student_mm[i,]$Major.2 <- last_rows[i,]$CURR_SPEC_PRIM_SUBJECT_2
  }
  
  # combined majors....
  
  # finding that minor
  if(last_rows[i,]$CURR_SPEC_PRIM_PGM_TYPE_1=="MIN"){
    student_mm[i,]$Minor <- last_rows[i,]$CURR_SPEC_PRIM_SUBJECT_1
  } else if (last_rows[i,]$CURR_SPEC_PRIM_PGM_TYPE_2=="MIN"){
    student_mm[i,]$Minor <- last_rows[i,]$CURR_SPEC_PRIM_SUBJECT_2
  }
  
  # adding Honors as majors
  if(last_rows[i,]$CURR_SPEC_PRIM_PGM_TYPE_1=="HON" & is.na(student_mm[i,]$Major.1)){
    student_mm[i,]$Major.1 <- last_rows[i,]$CURR_SPEC_PRIM_SUBJECT_1
    student_mm[i,]$Honors <- TRUE
  } else if (last_rows[i,]$CURR_SPEC_PRIM_PGM_TYPE_1=="HON" & is.na(student_mm[i,]$Major.2)){
    student_mm[i,]$Major.2 <- last_rows[i,]$CURR_SPEC_PRIM_SUBJECT_1
    student_mm[i,]$Honors <- TRUE
  }
  if(last_rows[i,]$CURR_SPEC_PRIM_PGM_TYPE_2=="HON" & is.na(student_mm[i,]$Major.1)){
    student_mm[i,]$Major.1 <- last_rows[i,]$CURR_SPEC_PRIM_SUBJECT_2
    student_mm[i,]$Honors <- TRUE
  } else if (last_rows[i,]$CURR_SPEC_PRIM_PGM_TYPE_2=="HON" & is.na(student_mm[i,]$Major.2)){
    student_mm[i,]$Major.2 <- last_rows[i,]$CURR_SPEC_PRIM_SUBJECT_2
    student_mm[i,]$Honors <- TRUE
  }
  
  # adding combined majors
  if(last_rows[i,]$CURR_SPEC_PRIM_PGM_TYPE_1=="CMJ"){
    student_mm[i,]$Major.1 <- last_rows[i,]$CURR_SPEC_PRIM_SUBJECT_1
    student_mm[i,]$Major.2 <- last_rows[i,]$CURR_SPEC_SECN_SUBJECT_1
  } else if (last_rows[i,]$CURR_SPEC_PRIM_PGM_TYPE_2=="CMJ" & !is.na(student_mm[i,]$Major.1)){
    student_mm[i,]$Major.2 <- last_rows[i,]$CURR_SPEC_PRIM_SUBJECT_2
  }
  
}
student_mm

#student_mm[student_mm$StudentID=="48791F0E12EB466C2B84020BAB61D1A2",]
#last_rows[last_rows$STUD_NO_ANONYMOUS=="AC1CEB14281A98ACC2CD74C73F361CBF",]
#student_mm[,-1]
```


```{r Making studentgrades with .1 .2 etc}
# Making the Data Frame
 ## Columns to add: Student ID, Major, Honors, Minor, Extras, 200 most common courses

# Building df after getting the data

studentgrades <- data.frame(Student_ID = sort(uniqueids))




# Create a data frame with NA values and course column names
new_columns <- data.frame(matrix(NA, nrow = nrow(studentgrades), ncol = length(course_names_dups)))
colnames(new_columns) <- course_names_dups

# Add course name columns to existing data frame
studentgrades <- cbind(studentgrades, student_mm[,-1], new_columns)


# Saving student grades into df
for (i in 1:nrow(df_bsc_relevant_courses)){
  rep <- 0
  # finding the index of course name .1
  coursecol <- grep(df_bsc_relevant_courses[i,]$COURSE_CODE, colnames(studentgrades))[1]
  
  # Moving over from .1 to .2 columns if a grade already exists
  while(!is.na(studentgrades[studentgrades$Student_ID==df_bsc_relevant_courses[i,]$STUD_NO_ANONYMOUS,coursecol+rep])){
    rep = rep+1
  }
  
  # Saving student grade into studentgrades df
  studentgrades[studentgrades$Student_ID==df_bsc_relevant_courses[i,]$STUD_NO_ANONYMOUS,coursecol+rep] <- df_bsc_relevant_courses[i,]$HDR_CRS_PCT_GRD
}

studentgrades[,c("Student_ID","MATH.101.1","MATH.101.2")]


```

```{r Making studentgrades using most recent grade}
studentgrades <- data.frame(Student_ID = sort(uniqueids))

# Create a data frame with NA values and course column names
new_columns <- data.frame(matrix(NA, nrow = nrow(studentgrades), ncol = length(course_names)))
colnames(new_columns) <- course_names

# Add course name columns to existing data frame
studentgrades <- cbind(studentgrades, student_mm[,-1], new_columns)


# Saving student grades into df
for (i in 1:nrow(df_bsc_relevant_courses)){
  
  # finding the index of course name .1
  coursecol <- grep(df_bsc_relevant_courses[i,]$COURSE_CODE, colnames(studentgrades))[1]
  
  # Saving student grade into studentgrades df
  studentgrades[studentgrades$Student_ID==df_bsc_relevant_courses[i,]$STUD_NO_ANONYMOUS,coursecol+rep] <- df_bsc_relevant_courses[i,]$HDR_CRS_PCT_GRD
}

studentgrades
```


```{r}
## OPTION TO REMOVE STUDENTS WITH FEW COURSES IN STUDENTGRADES
non_null_counts <- apply(studentgrades[, -1], 1, function(row) sum(!is.na(row)))

# Create a new dataframe with student ID and non-null counts
result_df <- data.frame(student_id = studentgrades[, 1], non_null_count = non_null_counts)

result_df[result_df$non_null_count >= 3,]
```

# EDA

```{r}
# Big ol graph of student grades
maths <- studentgrades[complete.cases(studentgrades$MATH.100.1, studentgrades$MATH.100.2), ]


maths.lm <- lm(maths$MATH.100.1~ maths$MATH.100.2)
summary(maths.lm)

plot(maths$MATH.100.1, maths$MATH.100.2)
abline(maths.lm)

## weird....
```

```{r}
mathstat <- studentgrades[complete.cases(studentgrades$MATH.100.1, studentgrades$STAT.230.1), ]

mathstat.lm <- lm(mathstat$MATH.100.1~ mathstat$STAT.230.1)
summary(mathstat.lm)

plot(mathstat$MATH.100.1, mathstat$STAT.230.1)
abline(mathstat.lm)

## this one is a little more normal
## could be issues with course retakers

## want to check on people who only had to take it once...
```


```{r}
edasubset <- studentgrades[complete.cases(studentgrades$MATH.100.1, studentgrades$PSYO.111.1), ]

edasubset.lm <- lm(edasubset$MATH.100.1~ edasubset$PSYO.111.1)
summary(edasubset.lm)

plot(edasubset$MATH.100.1, edasubset$PSYO.111.1)
abline(edasubset.lm)

## ... makes sense that some courses like PSYO 111 are grade boosters
```

```{r}
mathstat2 <- studentgrades[complete.cases(studentgrades$MATH.100.2, studentgrades$STAT.230.1), ]

mathstat2.lm <- lm(mathstat2$MATH.100.2~ mathstat2$STAT.230.1)
summary(mathstat2.lm)

plot(mathstat2$MATH.100.2, mathstat2$STAT.230.1)
abline(mathstat2.lm)

## want to check on people who only had to take it once...

firsttimer <- anti_join(mathstat,mathstat2)
first.lm <- lm(firsttimer$MATH.100.1~ firsttimer$STAT.230.1)
summary(first.lm)

plot(firsttimer$MATH.100.1, firsttimer$STAT.230.1, xlim = c(0,100))
abline(first.lm)

# just removed the 'low' grades (p much all fails) 
```


```{r}
# want the average grade for each course... bar plot
course_averages <- data.frame(Courses = course_names_dups, Average = rep(NA, length(course_names_dups)))

for (i in 1:nrow(course_averages)){
  course_averages[i,]$Average <- mean(studentgrades[,course_averages[i,1]],na.rm = TRUE)
}
```

```{r}
barplot(course_averages$Average, names.arg = course_averages$Courses)

subset(course_averages, Courses == "PSYO.380.4")

studentgrades[!is.na(studentgrades$PSYO.380.4),c("Student_ID","PSYO.380.4")]

course_averages
```

```{r}
plot(studentgrades[!is.na(studentgrades$MATH.100.1)&!is.na(studentgrades$MATH.101.1)&!is.na(studentgrades$STAT.230.1)&!is.na(studentgrades$DATA.101.1),c("Student_ID","MATH.100.1","MATH.101.1","STAT.230.1","DATA.101.1")])

studentgrades[!is.na(studentgrades$STAT.230.1),c("Student_ID","MATH.100.1","MATH.101.1","DATA.101.1","STAT.230.1")]

plot(studentgrades[!is.na(studentgrades$STAT.230.1),c("Student_ID","MATH.100.1","MATH.101.1","DATA.101.1","STAT.230.1")])
```
```{r}
plot(studentgrades[!is.na(studentgrades$MATH.100.1)&!is.na(studentgrades$MATH.101.1),c("MATH.100.1","MATH.101.1")])


```



```{r missForest Impute into RF}
# preparing all student grades with stat230
stat230grades <- studentgrades[!is.na(studentgrades$STAT.230.1),c("Student_ID","MATH.100.1","MATH.101.1","STAT.230.1","MATH.200.1","MATH.221.1","COSC.211.1","COSC.222.1","COSC.221.1")]
stat230grades

library(missForest)
library(randomForest)

n_rows <- nrow(stat230grades)

train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing



stat230.imputed <- missForest(stat230grades[,2:5])$ximp

stat230.rf <- randomForest(STAT.230.1~., data=stat230.imputed[train_indices,] )
stat230.pred <- predict(stat230.rf, newdata = stat230.imputed[test_indices,])

stat230.real <- stat230grades[test_indices,]$STAT.230.1

# MSE value to compare to other models
mse <- mean((stat230.pred - stat230.real)^2)
mse
```

```{r missForest Impute into RF NEW USING NEW studentgrades}
# preparing all student grades with stat230
stat230grades <- studentgrades[!is.na(studentgrades$STAT.230),c("Student_ID","MATH.100","MATH.101","STAT.230","MATH.200","MATH.221","COSC.211","COSC.222","COSC.221")]
stat230grades

library(missForest)
library(randomForest)

n_rows <- nrow(stat230grades)

train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing



stat230.imputed <- missForest(stat230grades[,2:5])$ximp

stat230.rf <- randomForest(STAT.230~., data=stat230.imputed[train_indices,] )
stat230.pred <- predict(stat230.rf, newdata = stat230.imputed[test_indices,])

stat230.real <- stat230grades[test_indices,]$STAT.230

# MSE value to compare to other models
mse <- mean((stat230.pred - stat230.real)^2)
mse
```

```{r RF on all non-NA data}
# getting all students with grades in all courses
stat230grades.full <- studentgrades[!is.na(studentgrades$MATH.100.1)&!is.na(studentgrades$MATH.101.1)&!is.na(studentgrades$STAT.230.1)&!is.na(studentgrades$DATA.101.1),c("Student_ID","MATH.100.1","MATH.101.1","STAT.230.1","DATA.101.1")]
stat230grades.full

n_rows <- nrow(stat230grades.full)

train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing

library(randomForest)

stat230.rf <- randomForest(STAT.230.1~., data=stat230grades.full[train_indices,2:5] )
stat230.pred <- predict(stat230.rf, newdata = stat230grades.full[test_indices,2:5])

stat230.real <- stat230grades.full[test_indices,2:5]$STAT.230.1

# MSE value to compare to other models
mse <- mean((stat230.pred - stat230.real)^2)
mse

## MSE of data without DATA101 is 175...
## looks like imputing data and running a randomforest is best so far
```

```{r GBM on partial-NA data}
# loading in data again
stat230grades <- studentgrades[!is.na(studentgrades$STAT.230.1),c("Student_ID","MATH.100.1","MATH.101.1","DATA.101.1","STAT.230.1")]
n_rows <- nrow(stat230grades)
train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing

library(gbm)

gbm_params <- list(
  distribution = "gaussian",  # Specify the distribution for regression
  n.trees = 100,               # Number of trees (iterations)
  interaction.depth = 4,       # Maximum depth of trees
  shrinkage = 0.1,             # Learning rate (shrinkage)
  bag.fraction = 0.5,          # Fraction of training data used for each tree
  train.fraction = 1.0,        # Fraction of training data used for training (1.0 for full dataset)
  n.minobsinnode = 10          # Minimum number of observations in terminal nodes
)

gbm_model <- gbm(STAT.230.1 ~ ., data = stat230grades[train_indices,2:5], distribution = gbm_params$distribution,
                 n.trees = gbm_params$n.trees, interaction.depth = gbm_params$interaction.depth,
                 shrinkage = gbm_params$shrinkage, bag.fraction = gbm_params$bag.fraction,
                 train.fraction = gbm_params$train.fraction, n.minobsinnode = gbm_params$n.minobsinnode)

# Print the summary of the trained model
print(summary(gbm_model))

# Make predictions on new data
# Assuming 'new_data' is your new dataframe for prediction
predictions <- predict(gbm_model, newdata = stat230grades[test_indices,2:5], n.trees = gbm_params$n.trees)

# Print the predictions
print(predictions)

mse <- mean((predictions - stat230grades[test_indices,2:5]$STAT.230.1)^2)
mse
## 175 mse... getting worse...
```

```{r GBM on non-NA data}
# loading in data again TRYING WITH FULL DATA
stat230grades <- studentgrades[!is.na(studentgrades$MATH.100.1)&!is.na(studentgrades$MATH.101.1)&!is.na(studentgrades$STAT.230.1)&!is.na(studentgrades$DATA.101.1),c("Student_ID","MATH.100.1","MATH.101.1","STAT.230.1","DATA.101.1")]
stat230grades
n_rows <- nrow(stat230grades)
train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing

library(gbm)

gbm_params <- list(
  distribution = "gaussian",  # Specify the distribution for regression
  n.trees = 100,               # Number of trees (iterations)
  interaction.depth = 4,       # Maximum depth of trees
  shrinkage = 0.1,             # Learning rate (shrinkage)
  bag.fraction = 0.5,          # Fraction of training data used for each tree
  train.fraction = 1.0,        # Fraction of training data used for training (1.0 for full dataset)
  n.minobsinnode = 10          # Minimum number of observations in terminal nodes
)

gbm_model <- gbm(STAT.230.1 ~ ., data = stat230grades[train_indices,2:5], distribution = gbm_params$distribution,
                 n.trees = gbm_params$n.trees, interaction.depth = gbm_params$interaction.depth,
                 shrinkage = gbm_params$shrinkage, bag.fraction = gbm_params$bag.fraction,
                 train.fraction = gbm_params$train.fraction, n.minobsinnode = gbm_params$n.minobsinnode)

# Print the summary of the trained model
print(summary(gbm_model))

# Make predictions on new data
# Assuming 'new_data' is your new dataframe for prediction
predictions <- predict(gbm_model, newdata = stat230grades[test_indices,2:5], n.trees = gbm_params$n.trees)

# Print the predictions
print(predictions)

mse <- mean((predictions - stat230grades[test_indices,2:5]$STAT.230.1)^2)
mse
## 128 mse which is a little better when you've got full data
```

```{r missForest impute into GBM}
# now, does imputing the data before GBM work better?
# preparing all student grades with stat230
stat230grades <- studentgrades[!is.na(studentgrades$STAT.230.1),c("Student_ID","MATH.100.1","MATH.101.1","DATA.101.1","STAT.230.1")]
stat230grades

library(missForest)
library(gbm)

n_rows <- nrow(stat230grades)

train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing



stat230.imputed <- missForest(stat230grades[,2:5])$ximp

gbm_params <- list(
  distribution = "gaussian",  # Specify the distribution for regression
  n.trees = 100,               # Number of trees (iterations)
  interaction.depth = 4,       # Maximum depth of trees
  shrinkage = 0.1,             # Learning rate (shrinkage)
  bag.fraction = 0.5,          # Fraction of training data used for each tree
  train.fraction = 1.0,        # Fraction of training data used for training (1.0 for full dataset)
  n.minobsinnode = 10          # Minimum number of observations in terminal nodes
)

gbm_model <- gbm(STAT.230.1 ~ ., data = stat230.imputed[train_indices,], distribution = gbm_params$distribution,
                 n.trees = gbm_params$n.trees, interaction.depth = gbm_params$interaction.depth,
                 shrinkage = gbm_params$shrinkage, bag.fraction = gbm_params$bag.fraction,
                 train.fraction = gbm_params$train.fraction, n.minobsinnode = gbm_params$n.minobsinnode)

# Print the summary of the trained model
print(summary(gbm_model))

# Make predictions on new data
# Assuming 'new_data' is your new dataframe for prediction
predictions <- predict(gbm_model, newdata = stat230.imputed[test_indices,], n.trees = gbm_params$n.trees)

# Print the predictions
print(predictions)

mse <- mean((predictions - stat230.imputed[test_indices,]$STAT.230.1)^2)
mse
## 109 mse.. better still
```


```{r Pipeline for taking a course grade to predict on}
# takes course (eg. COSC 322)
# finds all predictors to predict on... run gbm.. take those with top influence?



stat230grades <- studentgrades[!is.na(studentgrades$STAT.230.1),-1:-5]




grade_counts <- colSums(!is.na(stat230grades))
# Subset columns with less than 10 grades
sparse_cols <- names(grade_counts[grade_counts < 10])
# Subset the dataframe to include only columns with more than 10 grades
stat230grades <- stat230grades[, -which(names(stat230grades) %in% sparse_cols)]





n_rows <- nrow(stat230grades)
train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing

library(gbm)

gbm_params <- list(
  distribution = "gaussian",  # Specify the distribution for regression
  n.trees = 100,               # Number of trees (iterations)
  interaction.depth = 4,       # Maximum depth of trees
  shrinkage = 0.1,             # Learning rate (shrinkage)
  bag.fraction = 0.5,          # Fraction of training data used for each tree
  train.fraction = 1.0,        # Fraction of training data used for training (1.0 for full dataset)
  n.minobsinnode = 10          # Minimum number of observations in terminal nodes
)

# ****CURRENT ERROR****** currently is stopping as some columns only contain few grades (only existing in test set) no bueno and cant train.
# TODO: remove those cols with few data
gbm_model <- gbm(STAT.230.1 ~ ., data = stat230grades[train_indices,], distribution = gbm_params$distribution,
                 n.trees = gbm_params$n.trees, interaction.depth = gbm_params$interaction.depth,
                 shrinkage = gbm_params$shrinkage, bag.fraction = gbm_params$bag.fraction,
                 train.fraction = gbm_params$train.fraction, n.minobsinnode = gbm_params$n.minobsinnode)

# Print the summary of the trained model
print(summary(gbm_model))

# Make predictions on new data
# Assuming 'new_data' is your new dataframe for prediction
predictions <- predict(gbm_model, newdata = stat230grades[test_indices,], n.trees = gbm_params$n.trees)

# Print the predictions
print(predictions)

mse <- mean((predictions - stat230grades[test_indices,]$STAT.230.1)^2)
mse
# 112.9313 eh
```



```{r MAIN TESTING}
### This first removes all courses which are in higher levels (eg. if predicting on STAT.230, 300's and 400's are removed)
### Then courses which have < 10 grades in them are removed (this is still by chance and may break) temp fix for NA courses in training set
### GBM used on remaining courses to predict for the course of interest
set.seed(5934)

# time to remove all future year courses from prediction
COI <- "STAT.230"
coursegrades <- studentgrades[!is.na(studentgrades[,COI]),-1:-5]

# figuring out the year level of each course...
YOI <- as.integer(substr(strsplit(COI, split = ".", fixed = TRUE)[[1]][2],1,1))

column_names <- colnames(coursegrades)

# Extract digits after the period in column names
column_digits <- as.integer(sub("^[^.]+\\.([0-9]).*", "\\1", column_names))

# Find columns with digits not matching the selected course year
cols_to_keep <- column_names[column_digits <= YOI]

# All columns in the same year or below
coursegrades <- coursegrades[, colnames(coursegrades) %in% cols_to_keep]

# extras/ to do next
grade_counts <- colSums(!is.na(coursegrades))
# Subset columns with less than 10 grades
sparse_cols <- names(grade_counts[grade_counts <= 5])

# Need to exclude future attempts at the course, but not past
## eg. PSYO.380.1 shouldn't use 380.2 as a predictor, but 380.2 can use 380.1
if(length(strsplit(COI, split = ".", fixed = TRUE)[[1]]) == 3){
  cname <- strsplit(COI, split = ".", fixed = TRUE)[[1]][1]
  cnum <- strsplit(COI, split = ".", fixed = TRUE)[[1]][2]
  crep <- as.integer(strsplit(COI, split = ".", fixed = TRUE)[[1]][3])
  # remove all future instances of course (if they exist)
  for(i in 1:length(column_names)){
    if(strsplit(column_names[i], split = ".", fixed = TRUE)[[1]][1] == cname & strsplit(column_names[i], split = ".", fixed = TRUE)[[1]][2] == cnum & as.integer(strsplit(column_names[i], split = ".", fixed = TRUE)[[1]][3]) > crep){
      sparse_cols <- append(sparse_cols, column_names[i])
    }
  }
}

# Subset the dataframe to include only courses used to predict on
coursegrades <- coursegrades[, -which(names(coursegrades) %in% sparse_cols)]
```


```{r}
set.seed(5934)
n_rows <- nrow(coursegrades)
train_indices <- sample(1:n_rows, 0.7 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing

library(gbm)

gbm_params <- list(
  distribution = "gaussian",  # Specify the distribution for regression
  n.trees = 250,               # Number of trees (iterations)
  interaction.depth = 4,       # Maximum depth of trees
  shrinkage = 0.05,             # Learning rate (shrinkage)
  bag.fraction = 0.5,          # Fraction of training data used for each tree
  train.fraction = 1.0,        # Fraction of training data used for training (1.0 for full dataset)
  n.minobsinnode = 10          # Minimum number of observations in terminal nodes
)



gbm_model <- gbm(STAT.230 ~ ., data = coursegrades[train_indices,], distribution = gbm_params$distribution,
                 n.trees = gbm_params$n.trees, interaction.depth = gbm_params$interaction.depth,
                 shrinkage = gbm_params$shrinkage, bag.fraction = gbm_params$bag.fraction,
                 train.fraction = gbm_params$train.fraction, n.minobsinnode = gbm_params$n.minobsinnode, cv.folds = 5)

# Print the summary of the trained model
print(summary(gbm_model))

# Make predictions on new data
# Assuming 'new_data' is your new dataframe for prediction
predictions <- predict(gbm_model, newdata = coursegrades[test_indices,], n.trees = gbm_params$n.trees)


# Print the predictions
#predictions

mse <- mean((predictions - coursegrades[test_indices,COI])^2)
mse

```


```{r removed current year grades from prediction}
## removes all courses of equal or higher level before prediction
set.seed(5934)
# time to remove all future year courses from prediction
COI <- "COSC.322"
coursegrades <- studentgrades[!is.na(studentgrades[,COI]),-1:-5]

# figuring out the year level of each course...
YOI <- as.integer(substr(strsplit(COI, split = ".", fixed = TRUE)[[1]][2],1,1))

column_names <- colnames(coursegrades)

# Extract digits after the period in column names
column_digits <- as.integer(sub("^[^.]+\\.([0-9]).*", "\\1", column_names))

# Find columns with digits not matching the selected course year
cols_to_keep <- column_names[column_digits < YOI]
cols_to_keep <- append(cols_to_keep, COI)

# All columns in the same year or below
coursegrades <- coursegrades[, colnames(coursegrades) %in% cols_to_keep]

# extras/ to do next
grade_counts <- colSums(!is.na(coursegrades))
# Subset columns with less than x grades
sparse_cols <- names(grade_counts[grade_counts <= 5])


# Subset the dataframe to include only courses used to predict on
coursegrades <- coursegrades[, -which(names(coursegrades) %in% sparse_cols)]
```


```{r}
set.seed(5934)
n_rows <- nrow(coursegrades)
train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing

library(gbm)

gbm_params <- list(
  distribution = "gaussian",  # Specify the distribution for regression
  n.trees = 100,               # Number of trees (iterations)
  interaction.depth = 4,       # Maximum depth of trees
  shrinkage = 0.1,             # Learning rate (shrinkage)
  bag.fraction = 0.5,          # Fraction of training data used for each tree
  train.fraction = 1.0,        # Fraction of training data used for training (1.0 for full dataset)
  n.minobsinnode = 10          # Minimum number of observations in terminal nodes
)



gbm_model <- gbm(COSC.322 ~ ., data = coursegrades[train_indices,], distribution = gbm_params$distribution,
                 n.trees = gbm_params$n.trees, interaction.depth = gbm_params$interaction.depth,
                 shrinkage = gbm_params$shrinkage, bag.fraction = gbm_params$bag.fraction,
                 train.fraction = gbm_params$train.fraction, n.minobsinnode = gbm_params$n.minobsinnode, cv.folds = 10)

# Print the summary of the trained model
print(summary(gbm_model))

# Make predictions on new data
# Assuming 'new_data' is your new dataframe for prediction
predictions <- predict(gbm_model, newdata = coursegrades[test_indices,], n.trees = gbm_params$n.trees)

# Print the predictions
predictions

mse <- mean((predictions - coursegrades[test_indices,COI])^2)
mse

```



```{r}
actual <- coursegrades[test_indices,]$STAT.230
plot(actual, predictions, xlab = "Actual Grades", ylab = "Predicted Grades", 
     main = "Predicted vs Actual Grades", pch = 16, col = "blue", xlim = c(0,100), ylim = c(0,100))
abline(0, 1, col = "red")

max(predictions)
max(actual)

line.lm <- lm(predictions~actual)
abline(line.lm, col = "green")
```




```{r}
residuals <- actual - predictions
plot(predictions, residuals, xlab = "Predicted Grades", ylab = "Residuals", 
     main = "Residual Plot", pch = 16, col = "blue")
abline(h = 0, col = "red")

line.lm <- lm(residuals~predictions)
abline(line.lm, col = "green")
```

```{r}
qqnorm(residuals, main = "Normal Q-Q Plot of Residuals")
qqline(residuals, col = "red")
```


```{r conf matrix and heat map}
# Define breaks for intervals of 5
breaks <- seq(0, 100, by = 5)

# Create labels for the intervals
labels <- paste(breaks[-length(breaks)], breaks[-1], sep = "-")

actual_fac <- cut(actual, breaks = breaks, labels = labels, right = TRUE, include.lowest = TRUE)
pred_fac <- cut(predictions, breaks = breaks, labels = labels, right = TRUE, include.lowest = TRUE)

confusion_matrix <- table(actual_fac, pred_fac)

# Print the confusion matrix

library(caret)

confusion_matrix <- confusionMatrix(confusion_matrix)
#confusion_matrix

# Print recall for each class
rec <- confusion_matrix$byClass[, "Recall"]
prec <- confusion_matrix$byClass[, "Precision"]
f1_score <- 2*prec*rec/(prec+rec)

library(ggplot2)

confusion_matrix$Freq[is.na(confusion_matrix$Freq)] <- 0

# Create the heat map
ggplot(as.data.frame(confusion_matrix$table), aes(x = actual_fac, y = pred_fac, fill = Freq)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "white", high = "red") +
  labs(x = "Actual Grades", y = "Predicted Grades", fill = "Frequency") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  geom_tile(data = subset(as.data.frame(confusion_matrix$table), actual_fac == pred_fac),
            aes(fill = Freq), color = "black")
```


```{r}
## sets all courses of equal or higher level to NA before prediction, but after training the model
set.seed(5934)
# time to remove all future year courses from prediction
COI <- "STAT.230.1"
coursegrades <- studentgrades[!is.na(studentgrades[,COI]),-1:-5]

# figuring out the year level of each course...
YOI <- as.integer(substr(strsplit(COI, split = ".", fixed = TRUE)[[1]][2],1,1))

column_names <- colnames(coursegrades)

# Extract digits after the period in column names
column_digits <- as.integer(sub("^[^.]+\\.([0-9]).*", "\\1", column_names))

# Find columns with digits not matching the selected course year
cols_to_keep <- column_names[column_digits <= YOI]
cols_to_keep <- append(cols_to_keep, COI)

# All columns in the same year or below
coursegrades <- coursegrades[, colnames(coursegrades) %in% cols_to_keep]

# extras/ to do next
grade_counts <- colSums(!is.na(coursegrades))
# Subset columns with less than 10 grades
sparse_cols <- names(grade_counts[grade_counts <= 5])

# Need to exclude future attempts at the course, but not past
## eg. PSYO.380.1 shouldn't use 380.2 as a predictor, but 380.2 can use 380.1
if(length(strsplit(COI, split = ".", fixed = TRUE)[[1]]) == 3){
  cname <- strsplit(COI, split = ".", fixed = TRUE)[[1]][1]
  cnum <- strsplit(COI, split = ".", fixed = TRUE)[[1]][2]
  crep <- as.integer(strsplit(COI, split = ".", fixed = TRUE)[[1]][3])
  # remove all future instances of course (if they exist)
  for(i in 1:length(column_names)){
    if(strsplit(column_names[i], split = ".", fixed = TRUE)[[1]][1] == cname & strsplit(column_names[i], split = ".", fixed = TRUE)[[1]][2] == cnum & as.integer(strsplit(column_names[i], split = ".", fixed = TRUE)[[1]][3]) > crep){
      sparse_cols <- append(sparse_cols, column_names[i])
    }
  }
}

# Subset the dataframe to include only courses used to predict on
coursegrades <- coursegrades[, -which(names(coursegrades) %in% sparse_cols)]
```

```{r}
set.seed(5934)
n_rows <- nrow(coursegrades)
train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing

cols_to_na <- column_names[column_digits == YOI] #### ADD BACK COURSE OF INTEREST!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
cols_to_na <- cols_to_na[!cols_to_na == COI]
coursegrades[test_indices, which(names(coursegrades) %in% cols_to_na)] <- NA
```


```{r}
library(gbm)

gbm_params <- list(
  distribution = "gaussian",  # Specify the distribution for regression
  n.trees = 100,               # Number of trees (iterations)
  interaction.depth = 4,       # Maximum depth of trees
  shrinkage = 0.1,             # Learning rate (shrinkage)
  bag.fraction = 0.5,          # Fraction of training data used for each tree
  train.fraction = 1.0,        # Fraction of training data used for training (1.0 for full dataset)
  n.minobsinnode = 10          # Minimum number of observations in terminal nodes
)



gbm_model <- gbm(STAT.230.1 ~ ., data = coursegrades[train_indices,], distribution = gbm_params$distribution,
                 n.trees = gbm_params$n.trees, interaction.depth = gbm_params$interaction.depth,
                 shrinkage = gbm_params$shrinkage, bag.fraction = gbm_params$bag.fraction,
                 train.fraction = gbm_params$train.fraction, n.minobsinnode = gbm_params$n.minobsinnode, cv.folds = 10)

# Print the summary of the trained model
print(summary(gbm_model))

# Make predictions on new data
# Assuming 'new_data' is your new dataframe for prediction
predictions <- predict(gbm_model, newdata = coursegrades[test_indices,], n.trees = gbm_params$n.trees)

# Print the predictions
predictions

mse <- mean((predictions - coursegrades[test_indices,COI])^2)
mse

```

```{r missForest Impute into RF}
set.seed(5934)
# preparing all student grades with stat230
stat230grades <- studentgrades[!is.na(studentgrades$STAT.230),c("Student_ID","MATH.100","MATH.101","STAT.230","MATH.200","MATH.221","COSC.211","COSC.222","COSC.221")]
stat230grades

library(missForest)
library(randomForest)

n_rows <- nrow(stat230grades)

train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing



stat230.imputed <- missForest(stat230grades[,2:9])$ximp

stat230.rf <- randomForest(STAT.230~., data=stat230.imputed[train_indices,] )
stat230.pred <- predict(stat230.rf, newdata = stat230.imputed[test_indices,])

stat230.real <- stat230grades[test_indices,]$STAT.230

# MSE value to compare to other models
mse <- mean((stat230.pred - stat230.real)^2)
mse
```

```{r}
predictions <- stat230.pred
actual <- stat230.real

actual <- coursegrades[test_indices,]$STAT.230
plot(actual, predictions, xlab = "Actual Grades", ylab = "Predicted Grades", 
     main = "Predicted vs Actual Grades", pch = 16, col = "blue", xlim = c(0,100), ylim = c(0,100))
abline(0, 1, col = "red")


line.lm <- lm(predictions~actual)
abline(line.lm, col = "green")
```

```{r}
residuals <- actual - predictions
plot(predictions, residuals, xlab = "Predicted Grades", ylab = "Residuals", 
     main = "Residual Plot", pch = 16, col = "blue")
abline(h = 0, col = "red")

line.lm <- lm(residuals~predictions)
abline(line.lm, col = "green")
```

```{r}
qqnorm(residuals, main = "Normal Q-Q Plot of Residuals")
qqline(residuals, col = "red")
```


```{r Using missForest for imputation}
set.seed(5934)
# preparing all student grades with stat230
stat230grades <- studentgrades[!is.na(studentgrades$STAT.230),-1:-5]
stat230grades

library(missForest)
library(randomForest)

n_rows <- nrow(stat230grades)

train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing

# to remove stat 230 grades from test_indicies rows
stat230.real <- stat230grades[test_indices,]$STAT.230
stat230grades[test_indices,]$STAT.230 <- NA

stat230.imputed <- missForest(stat230grades)$ximp

#stat230.rf <- randomForest(STAT.230~., data=stat230.imputed[train_indices,] )
#stat230.pred <- predict(stat230.rf, newdata = stat230.imputed[test_indices,])
stat230.pred <- stat230.imputed[test_indices,]$STAT.230


# MSE value to compare to other models
mse <- mean((stat230.pred - stat230.real)^2)
mse
```

```{r}
predictions <- stat230.pred
actual <- stat230.real

actual <- coursegrades[test_indices,]$STAT.230
plot(actual, predictions, xlab = "Actual Grades", ylab = "Predicted Grades", 
     main = "Predicted vs Actual Grades", pch = 16, col = "blue", xlim = c(0,100), ylim = c(0,100))
abline(0, 1, col = "red")


line.lm <- lm(predictions~actual)
abline(line.lm, col = "green")
```

```{r}
residuals <- actual - predictions
plot(predictions, residuals, xlab = "Predicted Grades", ylab = "Residuals", 
     main = "Residual Plot", pch = 16, col = "blue")
abline(h = 0, col = "red")

line.lm <- lm(residuals~predictions)
abline(line.lm, col = "green")
```

```{r}
qqnorm(residuals, main = "Normal Q-Q Plot of Residuals")
qqline(residuals, col = "red")
```


```{r Simple models}
coursegrades <- studentgrades[!is.na(studentgrades$STAT.230)&!is.na(studentgrades$MATH.101)&!is.na(studentgrades$COSC.221),c("STAT.230","MATH.101","COSC.221")]
coursegrades
```



```{r}
set.seed(5934)

library(missForest)
library(randomForest)

n_rows <- nrow(coursegrades)

train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing



stat230.rf <- randomForest(STAT.230~., data=coursegrades[train_indices,] )
stat230.pred <- predict(stat230.rf, newdata = coursegrades[test_indices,])



# MSE value to compare to other models
mse <- mean((stat230.pred - stat230.real)^2)
mse
```

```{r}
subset(studentgrades, Major.1 == "DATA" | Major.2== "DATA" | Minor=="DATA")
```

```{r Trying less predictors}
# Getting list of students wanted
studs <- studentgrades[!is.na(studentgrades$STAT.230)&!is.na(studentgrades$MATH.101)&!is.na(studentgrades$COSC.221),]$Student_ID



data <- data.frame(student = character(), course=character(), grade=double())
for(id in studs){
  data <- rbind(data, list(id,"STAT.230",studentgrades[studentgrades$Student_ID==id,"STAT.230"]))
  data <- rbind(data, list(id,"MATH.101",studentgrades[studentgrades$Student_ID==id,"MATH.101"]))
  data <- rbind(data, list(id,"COSC.221",studentgrades[studentgrades$Student_ID==id,"COSC.221"]))
}

colnames(data) <- c("student","course","grade")

data <- na.omit(data)  # Remove rows with NA ratings

# Split into obj course and not
data_obj <- data[data$course=="STAT.230",]
data_non <- data[!data$course=="STAT.230",]

# Creating the testing set from obj course
n_rows <- nrow(data_obj)

train_indices <- sample(1:n_rows, 0.9 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing

data <- rbind(data_obj[test_indices,], data_obj[train_indices,],data_non)


# Factoring data
data[] <- lapply(data, function(x) {
  if (is.character(x)) {
    as.numeric(factor(x))
  } else {
    x
  }
})

obj_course <- data[1,2]
```

```{r}
#studs
# Create an empty plot
plot(NA, xlim=c(1, length(unique(df$course_name))), ylim = range(data$grade),
     xlab = "Course Name", ylab = "Course Grade", type = "n", xaxt = "n")

# Customize x-axis with course names
axis(1, at = 1:length(unique(data$course)), labels = unique(data$course))

# Plot lines for each student
for (ids in data[data$grade<= 70 & data$grade >= 69 & data$course==obj_course,]$student) {
  student_data <- data[data$student == ids, ]
  course_indices <- as.numeric(factor(student_data$course, levels = unique(data$course)))
  lines(course_indices, student_data$grade, type = "b", col = ids, lwd = 2, pch = 19)
}
```


```{r Dataset creation for MF}
# Getting list of students wanted
studs <- studentgrades[!is.na(studentgrades$STAT.230),]$Student_ID

data <- data.frame(student = character(), course=character(), grade=double())
for(id in studs){
  for(c in 6:205){
    if(!is.na(studentgrades[studentgrades$Student_ID==id,c])){
      data <- rbind(data, list(id,colnames(studentgrades)[c],studentgrades[studentgrades$Student_ID==id,c]))
    }
  }
}

colnames(data) <- c("student","course","grade")

data <- na.omit(data)  # Remove rows with NA ratings

# Split into obj course and not
data_obj <- data[data$course=="STAT.230",]
data_non <- data[!data$course=="STAT.230",]

# Creating the testing set from obj course
n_rows <- nrow(data_obj)

train_indices <- sample(1:n_rows, 0.9 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing

data <- rbind(data_obj[test_indices,], data_obj[train_indices,],data_non)


# Factoring data
data[] <- lapply(data, function(x) {
  if (is.character(x)) {
    as.numeric(factor(x))
  } else {
    x
  }
})

obj_course <- data[1,2]
```


```{r Matrix Factorization}
library(recosystem)

# Create a Reco object
r <- Reco()

# Define the training set
train_set <- data_memory(user_index = data$student[-1:-length(test_indices)], item_index = data$course[-1:-length(test_indices)], rating = data$grade[-1:-length(test_indices)])

# Train the model with ALS
r$train(train_set, opts = list(dim = 10, costp_l2 = 0.2, costq_l2 = 0.2, lrate = 0.05, niter = 20))


# Initialize the matrix to store predicted grades
predicted_grades <- data[1:length(test_indices),]
predicted_grades$grade <- NA

# Predict missing values

for(i in 1:nrow(predicted_grades)){
  predicted_grades[i,]$grade <- r$predict(data_memory(user_index = predicted_grades[i,]$student, item_index = predicted_grades[i,]$course))
}


# Print the predicted grades matrix
print(predicted_grades)


# Calculate MSE for observed (non-NA) grades
observed_indices <- which(!is.na(grades))
mse <- mean((predicted_grades$grade - data_obj[test_indices,]$grade)^2)
cat("Mean Squared Error (MSE):", mse, "\n")



```

```{r}
actual <- data[test_indices,]$grade
predictions <- predicted_grades$grade
plot(actual, predictions, xlab = "Actual Grades", ylab = "Predicted Grades", 
     main = "Predicted vs Actual Grades", pch = 16, col = "blue", xlim = c(0,100), ylim = c(0,100))
abline(0, 1, col = "red")

line.lm <- lm(predictions~actual)
abline(line.lm, col = "green")

mse <- mean((predictions - actual)^2)
cat("Mean Squared Error (MSE):", mse, "\n")
```

```{r}
residuals <- actual - predictions
plot(predictions, residuals, xlab = "Predicted Grades", ylab = "Residuals", 
     main = "Residual Plot", pch = 16, col = "blue")
abline(h = 0, col = "red")

line.lm <- lm(residuals~predictions)
abline(line.lm, col = "green")
```

```{r}
qqnorm(residuals, main = "Normal Q-Q Plot of Residuals")
qqline(residuals, col = "red")
```

```{r}
# returns the number of times a course has been taken by students who have also taken stat 230
ids <- unique(df_bsc[df_bsc$COURSE_CODE=="STAT.230",]$STUD_NO_ANONYMOUS)
courses <- unique(df_bsc[df_bsc$STUD_NO_ANONYMOUS %in% ids,]$COURSE_CODE)
new_courses <- character(0)
for(i in 1:length(courses)){
  if(strsplit(courses[i], split = ".", fixed = TRUE)[[1]][2] < 300){
    new_courses <- append(new_courses, courses[i])
  }
}

courses_taken_bsc_stat230 <- table(df_bsc[df_bsc$STUD_NO_ANONYMOUS %in% ids & df_bsc$COURSE_CODE %in% new_courses,]$COURSE_CODE)


sorted_courses_taken_bsc <- sort(courses_taken_bsc_stat230, decreasing = TRUE)
course_names <- sorted_courses_taken_bsc[sorted_courses_taken_bsc >= 250]
# number of courses who have been taken by at least 25 people: 87
length(sorted_courses_taken_bsc[sorted_courses_taken_bsc >= 250])


strsplit("STAT.230", split = ".", fixed = TRUE)[[1]][2]
```


```{r missForest Impute on some courses}
# preparing all student grades with stat230
stat230grades <- studentgrades[!is.na(studentgrades$STAT.230),c("Student_ID","MATH.100","MATH.101","STAT.230","MATH.200","MATH.221","COSC.211","COSC.222","COSC.221")]
stat230grades

library(missForest)
library(randomForest)

n_rows <- nrow(stat230grades)

train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing



stat230.imputed <- missForest(stat230grades[,2:9])$ximp

stat230.rf <- randomForest(STAT.230~., data=stat230.imputed[train_indices,])
stat230.pred <- predict(stat230.rf, newdata = stat230.imputed[test_indices,])

stat230.real <- stat230grades[test_indices,]$STAT.230

# MSE value to compare to other models
mse <- mean((stat230.pred - stat230.real)^2)
mse
```

```{r missForest Impute on all courses}
# returns the number of times a course has been taken by students who have also taken stat 230
ids <- unique(df_bsc[df_bsc$COURSE_CODE=="STAT.230",]$STUD_NO_ANONYMOUS)
courses <- unique(df_bsc[df_bsc$STUD_NO_ANONYMOUS %in% ids,]$COURSE_CODE)
new_courses <- character(0)
for(i in 1:length(courses)){
  if(strsplit(courses[i], split = ".", fixed = TRUE)[[1]][2] < 300){
    new_courses <- append(new_courses, courses[i])
  }
}

courses_taken_bsc_stat230 <- table(df_bsc[df_bsc$STUD_NO_ANONYMOUS %in% ids & df_bsc$COURSE_CODE %in% new_courses,]$COURSE_CODE)


sorted_courses_taken_bsc <- sort(courses_taken_bsc_stat230, decreasing = TRUE)
course_names <- sorted_courses_taken_bsc[sorted_courses_taken_bsc >= 190]



set.seed(45)

# of the same year and below
# preparing all student grades with stat230
course_names <- dimnames(course_names)[[1]]


stat230grades <- studentgrades[!is.na(studentgrades$STAT.230),colnames(studentgrades) %in% course_names]
stat230grades

library(missForest)
library(randomForest)

n_rows <- nrow(stat230grades)

train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing



stat230.imputed <- missForest(stat230grades[,-1])$ximp

stat230.rf <- randomForest(STAT.230~., data=stat230.imputed[train_indices,])
stat230.pred <- predict(stat230.rf, newdata = stat230.imputed[test_indices,])

stat230.real <- stat230grades[test_indices,]$STAT.230

# MSE value to compare to other models
rmse <- sqrt(mean((stat230.pred - stat230.real)^2))
rmse
```

```{r}
actual <- stat230.real
predictions <- stat230.pred
plot(actual, predictions, xlab = "Actual Grades", ylab = "Predicted Grades", 
     main = "Predicted vs Actual Grades", pch = 16, col = "blue", xlim = c(0,100), ylim = c(0,100))
abline(0, 1, col = "red")
abline(h = 50, col = "pink", lty = 2)
abline(h = 60, col = "pink", lty = 2)
abline(h = 70, col = "pink", lty = 2)# pink dashed line

abline(v = 50, col = "pink", lty = 2)
abline(v = 60, col = "pink", lty = 2)
abline(v = 70, col = "pink", lty = 2)

line.lm <- lm(predictions~actual)
abline(line.lm, col = "green")

mse <- mean((predictions - actual)^2)
cat("Mean Squared Error (MSE):", mse, "\n")


#sum(predictions<50)
#sum(actual<50)
```

```{r}
residuals <- actual - predictions
plot(predictions, residuals, xlab = "Predicted Grades", ylab = "Residuals", 
     main = "Residual Plot", pch = 16, col = "blue")
abline(h = 0, col = "red")

line.lm <- lm(residuals~predictions)
abline(line.lm, col = "green")
```

```{r}
qqnorm(residuals, main = "Normal Q-Q Plot of Residuals")
qqline(residuals, col = "red")
```

```{r missForest Impute on all courses TESTING FOR RANDOM COURSES}
# returns the number of times a course has been taken by students who have also taken xxxx.xxx
ids <- unique(df_bsc[df_bsc$COURSE_CODE=="COSC.221",]$STUD_NO_ANONYMOUS)
courses <- unique(df_bsc[df_bsc$STUD_NO_ANONYMOUS %in% ids,]$COURSE_CODE)
new_courses <- character(0)
for(i in 1:length(courses)){
  if(strsplit(courses[i], split = ".", fixed = TRUE)[[1]][2] < 300){
    new_courses <- append(new_courses, courses[i])
  }
}

courses_taken_bsc_stat230 <- table(df_bsc[df_bsc$STUD_NO_ANONYMOUS %in% ids & df_bsc$COURSE_CODE %in% new_courses,]$COURSE_CODE)


sorted_courses_taken_bsc <- sort(courses_taken_bsc_stat230, decreasing = TRUE)
course_names <- sorted_courses_taken_bsc[sorted_courses_taken_bsc >= 50]



set.seed(45)

# of the same year and below
# preparing all student grades with stat230
course_names <- dimnames(course_names)[[1]]


stat230grades <- studentgrades[!is.na(studentgrades$COSC.221),colnames(studentgrades) %in% course_names]
stat230grades

library(missForest)
library(randomForest)

n_rows <- nrow(stat230grades)

train_indices <- sample(1:n_rows, 0.8 * n_rows)  # 80% of rows for training
test_indices <- setdiff(1:n_rows, train_indices) # remaining rows for testing



stat230.imputed <- missForest(stat230grades[,-1])$ximp

stat230.rf <- randomForest(COSC.221~., data=stat230.imputed[train_indices,])
stat230.pred <- predict(stat230.rf, newdata = stat230.imputed[test_indices,])

stat230.real <- stat230grades[test_indices,]$COSC.221

# MSE value to compare to other models
rmse <- sqrt(mean((stat230.pred - stat230.real)^2))
rmse
```

```{r}
actual <- stat230.real
predictions <- stat230.pred
plot(actual, predictions, xlab = "Actual Grades", ylab = "Predicted Grades", 
     main = "Predicted vs Actual Grades", pch = 16, col = "blue", xlim = c(0,100), ylim = c(0,100))
abline(0, 1, col = "red")
abline(h = 50, col = "pink", lty = 2)
abline(h = 60, col = "pink", lty = 2)
abline(h = 70, col = "pink", lty = 2)# pink dashed line

abline(v = 50, col = "pink", lty = 2)
abline(v = 60, col = "pink", lty = 2)
abline(v = 70, col = "pink", lty = 2)

line.lm <- lm(predictions~actual)
abline(line.lm, col = "green")

mse <- mean((predictions - actual)^2)
cat("Mean Squared Error (MSE):", mse, "\n")


sum(predictions<50)
sum(actual<50)
```

```{r Pairwise Correlation}
library(bnlearn)
suppressWarnings({
pc <- pc.stable(studentgrades[,-(1:5)], undirected = FALSE)
pc$arcs # 10 arcs

gs <- gs(studentgrades[,-(1:5)], undirected = FALSE)
gs$arcs # 10 arcs

iamb <- iamb(studentgrades[,-(1:5)])
iamb$arcs # 75 arc... some potential

hc <- tabu(studentgrades[,-(1:5)], score = "aic")
hc$arcs

mmhc <- h2pc(studentgrades[,-(1:5)])
mmhc$arcs

mmpc <- mmpc(studentgrades[,-(1:5)])
mmpc$arcs # lots of pairs but no substance
})
```

```{r}
chow <- chow.liu(studentgrades[,-(1:5)])
chow$arcs[chow$arcs[,1]=="STAT.230"]

mmpc$arcs[mmpc$arcs[,1]=="STAT.230"]
```

